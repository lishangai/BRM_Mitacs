{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5dde2534",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 卵巢癌化疗耐药性单细胞RNA-seq分析\n",
    "\n",
    "**数据集**: GSE300897  \n",
    "**核心基因**: BRM (SMARCA2)  \n",
    "**研究目标**: \n",
    "1. 探索化疗耐药（chemo-refractory）与化疗敏感（chemo-sensitive）卵巢癌样本在单细胞层面的差异\n",
    "2. 鉴定不同细胞亚群，理解肿瘤微环境（TME）的构成\n",
    "3. 验证IFN-I（I型干扰素）和缺氧通路在耐药机制中的作用\n",
    "4. 深入分析 `BRM (SMARCA2)` 基因的表达模式及其与耐药性的关联\n",
    "5. 为后续使用 `Geneformer` 进行 `BRM` 敲除模拟生成必要的输入文件\n",
    "\n",
    "---\n",
    "\n",
    "## 数据集基本信息\n",
    "\n",
    "- **样本数量**: 9个高级别浆液性卵巢癌（HGSC）患者样本\n",
    "- **分组**: 化疗耐药组（4个样本）vs 化疗敏感组（5个样本）\n",
    "- **数据类型**: 单细胞RNA测序（scRNA-seq）\n",
    "- **关键发现**: 耐药性与I型干扰素活性降低和缺氧通路活性增强相关\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ 重要提示\n",
    "\n",
    "**安装依赖包前请阅读**：\n",
    "- 建议在专门的conda环境中运行此分析\n",
    "- 如果遇到内核崩溃，请重启内核后逐个安装包\n",
    "- 某些包需要较长时间安装，请耐心等待\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1be8c69",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 环境准备：分步安装依赖包\n",
    "\n",
    "为了避免内核崩溃，我们将分步骤安装依赖包。**请按顺序执行以下单元格**，每个单元格执行完成后再执行下一个。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ed55622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python版本: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]\n",
      "安装核心科学计算包...\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pandas in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: scipy in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (1.15.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 步骤1: 安装核心科学计算包\n",
    "import sys\n",
    "print(f\"Python版本: {sys.version}\")\n",
    "print(\"安装核心科学计算包...\")\n",
    "\n",
    "%pip install pandas numpy matplotlib seaborn scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69b25233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "安装scanpy...\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: scanpy in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (1.11.3)\n",
      "Requirement already satisfied: anndata>=0.8 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (0.11.4)\n",
      "Requirement already satisfied: h5py>=3.7.0 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (3.14.0)\n",
      "Requirement already satisfied: joblib in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (1.5.1)\n",
      "Requirement already satisfied: legacy-api-wrap>=1.4.1 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (1.4.1)\n",
      "Requirement already satisfied: matplotlib>=3.7.5 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (3.10.0)\n",
      "Requirement already satisfied: natsort in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (8.4.0)\n",
      "Requirement already satisfied: networkx>=2.7.1 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (3.5)\n",
      "Requirement already satisfied: numba>=0.57.1 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (0.61.2)\n",
      "Requirement already satisfied: numpy>=1.24.1 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (1.26.4)\n",
      "Requirement already satisfied: packaging>=21.3 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (24.2)\n",
      "Requirement already satisfied: pandas>=1.5.3 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (2.2.3)\n",
      "Requirement already satisfied: patsy!=1.0.0 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (1.0.1)\n",
      "Requirement already satisfied: pynndescent>=0.5.13 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (0.5.13)\n",
      "Requirement already satisfied: scikit-learn>=1.1.3 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (1.7.0)\n",
      "Requirement already satisfied: scipy<1.16.0,>=1.8.1 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (1.15.3)\n",
      "Requirement already satisfied: seaborn>=0.13.2 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (0.13.2)\n",
      "Requirement already satisfied: session-info2 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (0.1.2)\n",
      "Requirement already satisfied: statsmodels>=0.14.4 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (0.14.5)\n",
      "Requirement already satisfied: tqdm in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (4.14.0)\n",
      "Requirement already satisfied: umap-learn>=0.5.6 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (0.5.9.post2)\n",
      "Requirement already satisfied: array-api-compat!=1.5,>1.4 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from anndata>=0.8->scanpy) (1.12.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from matplotlib>=3.7.5->scanpy) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from matplotlib>=3.7.5->scanpy) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from matplotlib>=3.7.5->scanpy) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from matplotlib>=3.7.5->scanpy) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from matplotlib>=3.7.5->scanpy) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from matplotlib>=3.7.5->scanpy) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from matplotlib>=3.7.5->scanpy) (2.9.0.post0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from numba>=0.57.1->scanpy) (0.44.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from pandas>=1.5.3->scanpy) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from pandas>=1.5.3->scanpy) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.7.5->scanpy) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scikit-learn>=1.1.3->scanpy) (3.6.0)\n",
      "Requirement already satisfied: colorama in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from tqdm->scanpy) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 步骤2: 安装scanpy (单细胞分析核心包)\n",
    "print(\"安装scanpy...\")\n",
    "%pip install scanpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83071d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试基本包导入...\n",
      "✓ 基本包导入成功\n"
     ]
    }
   ],
   "source": [
    "# 步骤3: 测试基本导入\n",
    "print(\"测试基本包导入...\")\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import scanpy as sc\n",
    "    print(\"✓ 基本包导入成功\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ 导入失败: {e}\")\n",
    "    print(\"请重启内核后重新运行前面的安装步骤\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b885dea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "安装可选的高级包...\n",
      "注意: 这些包是可选的，如果安装失败可以跳过\n",
      "尝试安装 gseapy...\n",
      "✓ gseapy 安装成功\n",
      "尝试安装 harmonypy...\n",
      "✓ harmonypy 安装成功\n"
     ]
    }
   ],
   "source": [
    "# 步骤4: 安装可选的高级包 (如果需要)\n",
    "print(\"安装可选的高级包...\")\n",
    "print(\"注意: 这些包是可选的，如果安装失败可以跳过\")\n",
    "\n",
    "# 安装通路富集分析包\n",
    "print(\"尝试安装 gseapy...\")\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"gseapy\"])\n",
    "    print(\"✓ gseapy 安装成功\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ gseapy 安装失败: {e}\")\n",
    "    print(\"可以跳过，后续会使用替代方法\")\n",
    "\n",
    "# 安装批次校正包\n",
    "print(\"尝试安装 harmonypy...\")\n",
    "try:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"harmonypy\"])\n",
    "    print(\"✓ harmonypy 安装成功\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ harmonypy 安装失败: {e}\")\n",
    "    print(\"可以跳过，后续会使用替代方法\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7e0e8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始安全的环境设置...\n",
      "✓ 基本库导入成功\n",
      "✓ scanpy 导入成功\n",
      "✓ scanpy 基本设置完成\n",
      "✓ matplotlib 导入成功\n",
      "✓ matplotlib 设置完成\n",
      "✓ 环境设置完成！\n",
      "如果上述步骤都显示成功，现在可以开始单细胞分析了。\n"
     ]
    }
   ],
   "source": [
    "# 步骤5: 安全的环境设置\n",
    "print(\"开始安全的环境设置...\")\n",
    "\n",
    "# 逐步导入和测试每个库\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ 基本库导入成功\")\n",
    "\n",
    "# 测试scanpy导入\n",
    "try:\n",
    "    import scanpy as sc\n",
    "    print(\"✓ scanpy 导入成功\")\n",
    "    \n",
    "    # 安全地设置scanpy参数\n",
    "    try:\n",
    "        sc.settings.verbosity = 1  # 降低日志级别避免过多输出\n",
    "        print(\"✓ scanpy 基本设置完成\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ scanpy 设置出现问题: {e}\")\n",
    "        print(\"使用默认设置继续\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"✗ scanpy 导入失败: {e}\")\n",
    "    print(\"请重新安装 scanpy: pip install scanpy\")\n",
    "    raise\n",
    "\n",
    "# 测试matplotlib导入和设置\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    print(\"✓ matplotlib 导入成功\")\n",
    "    \n",
    "    # 设置基本绘图参数\n",
    "    plt.rcParams['figure.figsize'] = (8, 6)\n",
    "    plt.rcParams['figure.dpi'] = 80\n",
    "    print(\"✓ matplotlib 设置完成\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"⚠️ matplotlib 设置出现问题: {e}\")\n",
    "\n",
    "print(\"✓ 环境设置完成！\")\n",
    "print(\"如果上述步骤都显示成功，现在可以开始单细胞分析了。\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "305515c2",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## 🔧 故障排除指南\n",
    "\n",
    "如果您在上面的步骤中遇到内核崩溃，请尝试以下解决方案：\n",
    "\n",
    "### 方案1: 重启并简化安装\n",
    "1. **重启内核** (Kernel → Restart)\n",
    "2. **只安装核心包**：\n",
    "   ```bash\n",
    "   pip install pandas numpy matplotlib scanpy\n",
    "   ```\n",
    "3. **跳过可选包**，先完成基本分析\n",
    "\n",
    "### 方案2: 使用conda环境\n",
    "```bash\n",
    "conda create -n scrna python=3.9\n",
    "conda activate scrna\n",
    "conda install -c conda-forge scanpy pandas matplotlib seaborn\n",
    "```\n",
    "\n",
    "### 方案3: 检查内存和环境\n",
    "- 确保有足够的RAM (建议8GB+)\n",
    "- 检查Python版本 (建议3.8-3.11)\n",
    "- 关闭其他占用内存的程序\n",
    "\n",
    "---\n",
    "\n",
    "## 步骤一：数据加载、预处理与质量控制 (QC)\n",
    "\n",
    "**⚠️ 重要**: 请确保上面的环境设置步骤全部显示 \"✓\" 后再继续。\n",
    "\n",
    "分析的第一步是加载原始数据，并进行严格的质量控制，过滤掉低质量的细胞和基因，确保后续分析的准确性。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3901e86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检查运行环境...\n",
      "✓ pandas\n",
      "✓ numpy\n",
      "✓ matplotlib.pyplot\n",
      "✓ seaborn\n",
      "✓ scanpy\n",
      "\n",
      "✅ 所有必要的包都已安装\n",
      "\n",
      "设置数据路径...\n",
      "✓ 创建输出目录: ../results/single_cell_analysis/\n",
      "\n",
      "检查数据文件...\n",
      "✓ UMI计数文件存在: ../data/raw/singlecell/UMIcounts_HGSC.tsv\n",
      "✓ 注释文件存在: ../data/raw/singlecell/annotation_HGSC.tsv\n",
      "\n",
      "🚀 环境检查完成，可以开始分析！\n"
     ]
    }
   ],
   "source": [
    "# 🔍 环境检查和数据路径设置\n",
    "print(\"检查运行环境...\")\n",
    "\n",
    "# 检查必要的包是否可用\n",
    "required_packages = {\n",
    "    'pandas': 'pd',\n",
    "    'numpy': 'np', \n",
    "    'matplotlib.pyplot': 'plt',\n",
    "    'seaborn': 'sns',\n",
    "    'scanpy': 'sc'\n",
    "}\n",
    "\n",
    "missing_packages = []\n",
    "for package, alias in required_packages.items():\n",
    "    try:\n",
    "        exec(f\"import {package} as {alias}\")\n",
    "        print(f\"✓ {package}\")\n",
    "    except ImportError:\n",
    "        print(f\"✗ {package} - 需要安装\")\n",
    "        missing_packages.append(package)\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"\\n⚠️ 缺少以下包: {', '.join(missing_packages)}\")\n",
    "    print(\"请先安装缺少的包后再继续\")\n",
    "else:\n",
    "    print(\"\\n✅ 所有必要的包都已安装\")\n",
    "    \n",
    "    # 设置数据路径\n",
    "    print(\"\\n设置数据路径...\")\n",
    "    counts_path = '../data/raw/singlecell/UMIcounts_HGSC.tsv'\n",
    "    annotation_path = '../data/raw/singlecell/annotation_HGSC.tsv'\n",
    "    output_dir = '../results/single_cell_analysis/'\n",
    "    \n",
    "    # 创建输出目录\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"✓ 创建输出目录: {output_dir}\")\n",
    "    else:\n",
    "        print(f\"✓ 输出目录已存在: {output_dir}\")\n",
    "        \n",
    "    # 检查数据文件\n",
    "    print(\"\\n检查数据文件...\")\n",
    "    if os.path.exists(counts_path):\n",
    "        print(f\"✓ UMI计数文件存在: {counts_path}\")\n",
    "    else:\n",
    "        print(f\"✗ UMI计数文件不存在: {counts_path}\")\n",
    "        print(\"请检查文件路径或下载数据文件\")\n",
    "        \n",
    "    if os.path.exists(annotation_path):\n",
    "        print(f\"✓ 注释文件存在: {annotation_path}\")\n",
    "    else:\n",
    "        print(f\"✗ 注释文件不存在: {annotation_path}\")\n",
    "        print(\"请检查文件路径或下载数据文件\")\n",
    "        \n",
    "    print(\"\\n🚀 环境检查完成，可以开始分析！\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 卵巢癌化疗耐药性单细胞RNA-seq分析\n",
    "\n",
    "**数据集**: GSE300897  \n",
    "**核心基因**: BRM (SMARCA2)  \n",
    "**研究目标**: \n",
    "1. 探索化疗耐药（chemo-refractory）与化疗敏感（chemo-sensitive）卵巢癌样本在单细胞层面的差异\n",
    "2. 鉴定不同细胞亚群，理解肿瘤微环境（TME）的构成\n",
    "3. 验证IFN-I（I型干扰素）和缺氧通路在耐药机制中的作用\n",
    "4. 深入分析 `BRM (SMARCA2)` 基因的表达模式及其与耐药性的关联\n",
    "5. 为后续使用 `Geneformer` 进行 `BRM` 敲除模拟生成必要的输入文件\n",
    "\n",
    "---\n",
    "\n",
    "## 数据集基本信息\n",
    "\n",
    "- **样本数量**: 9个高级别浆液性卵巢癌（HGSC）患者样本\n",
    "- **分组**: 化疗耐药组（4个样本）vs 化疗敏感组（5个样本）\n",
    "- **数据类型**: 单细胞RNA测序（scRNA-seq）\n",
    "- **关键发现**: 耐药性与I型干扰素活性降低和缺氧通路活性增强相关\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4050f4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 系统信息 ===\n",
      "操作系统: Windows 10\n",
      "Python版本: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]\n",
      "总内存: 15.19 GB\n",
      "可用内存: 6.54 GB\n",
      "CPU核心数: 16\n",
      "✅ 内存充足，可以进行分析\n"
     ]
    }
   ],
   "source": [
    "# 检查系统资源和环境\n",
    "import psutil\n",
    "import sys\n",
    "import platform\n",
    "\n",
    "print(\"=== 系统信息 ===\")\n",
    "print(f\"操作系统: {platform.system()} {platform.release()}\")\n",
    "print(f\"Python版本: {sys.version}\")\n",
    "print(f\"总内存: {psutil.virtual_memory().total / (1024**3):.2f} GB\")\n",
    "print(f\"可用内存: {psutil.virtual_memory().available / (1024**3):.2f} GB\")\n",
    "print(f\"CPU核心数: {psutil.cpu_count()}\")\n",
    "\n",
    "# 检查是否有足够内存进行分析\n",
    "if psutil.virtual_memory().available < 4 * 1024**3:  # 小于4GB\n",
    "    print(\"⚠️  警告: 可用内存可能不足，建议关闭其他程序或使用更小的数据集进行测试\")\n",
    "else:\n",
    "    print(\"✅ 内存充足，可以进行分析\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 环境准备：安装必要的Python库\n",
    "\n",
    "首先，我们需要安装分析所需的核心库。`scanpy` 是单细胞分析的主力，`gseapy` 用于通路富集分析，而 `scikit-misc` 提供了一些高级统计功能。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0e8fe25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting scanpy\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/34/cd/50e2af91c8d64722958cc53ca59f3e2bdc05ae4a5b82d78672cfd2ec7b3c/scanpy-1.11.3-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: gseapy in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (1.1.9)\n",
      "Collecting scikit-misc\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/98/7a/0ef8646dac8bcac7151c5dd3e604a33c497d6d093f4db538e25656144394/scikit_misc-0.5.1-cp311-cp311-win_amd64.whl (157 kB)\n",
      "Collecting harmony-pytorch\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/75/da/42486f1c79b6f2db9140ee23161791e5b25d9369f30c1d9f67b67f3eb4bf/harmony_pytorch-0.1.8-py3-none-any.whl (8.5 kB)\n",
      "Requirement already satisfied: pandas in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (0.13.2)\n",
      "Collecting anndata>=0.8 (from scanpy)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/0a/4b/ab615fea52e34579d5c6c7dba86b4f9d7f3cdb6a170b348ec49f34cf4355/anndata-0.11.4-py3-none-any.whl (144 kB)\n",
      "Collecting h5py>=3.7.0 (from scanpy)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/db/0c/6c3f879a0f8e891625817637fad902da6e764e36919ed091dc77529004ac/h5py-3.14.0-cp311-cp311-win_amd64.whl (2.9 MB)\n",
      "     ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 0.3/2.9 MB ? eta -:--:--\n",
      "     ------- -------------------------------- 0.5/2.9 MB 985.5 kB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 0.8/2.9 MB 1.3 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 1.6/2.9 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 2.4/2.9 MB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.9/2.9 MB 2.6 MB/s eta 0:00:00\n",
      "Collecting joblib (from scanpy)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/7d/4f/1195bbac8e0c2acc5f740661631d8d750dc38d4a32b23ee5df3cde6f4e0d/joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Collecting legacy-api-wrap>=1.4.1 (from scanpy)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/3c/1d/9324c70629dfe4395f9122ab331cf245d3cce6ded851aa8a0a8ae264c4e6/legacy_api_wrap-1.4.1-py3-none-any.whl (10.0 kB)\n",
      "Collecting natsort (from scanpy)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/ef/82/7a9d0550484a62c6da82858ee9419f3dd1ccc9aa1c26a1e43da3ecd20b0d/natsort-8.4.0-py3-none-any.whl (38 kB)\n",
      "Collecting networkx>=2.7.1 (from scanpy)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/eb/8d/776adee7bbf76365fdd7f2552710282c79a4ead5d2a46408c9043a2b70ba/networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "     ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 2.0/2.0 MB 12.6 MB/s eta 0:00:00\n",
      "Collecting numba>=0.57.1 (from scanpy)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/0f/a4/2b309a6a9f6d4d8cfba583401c7c2f9ff887adb5d54d8e2e130274c0973f/numba-0.61.2-cp311-cp311-win_amd64.whl (2.8 MB)\n",
      "     ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "     ------------------------------------- -- 2.6/2.8 MB 12.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.8/2.8 MB 12.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.24.1 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (1.26.4)\n",
      "Requirement already satisfied: packaging>=21.3 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (24.2)\n",
      "Collecting patsy!=1.0.0 (from scanpy)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/87/2b/b50d3d08ea0fc419c183a84210571eba005328efa62b6b98bc28e9ead32a/patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Collecting pynndescent>=0.5.13 (from scanpy)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/d2/53/d23a97e0a2c690d40b165d1062e2c4ccc796be458a1ce59f6ba030434663/pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
      "Collecting scikit-learn>=1.1.3 (from scanpy)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f4/5a/ba91b8c57aa37dbd80d5ff958576a9a8c14317b04b671ae7f0d09b00993a/scikit_learn-1.7.0-cp311-cp311-win_amd64.whl (10.7 MB)\n",
      "     ---------------------------------------- 0.0/10.7 MB ? eta -:--:--\n",
      "     ----------- ---------------------------- 3.1/10.7 MB 16.9 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 3.4/10.7 MB 8.1 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 6.8/10.7 MB 10.8 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 7.3/10.7 MB 8.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 9.7/10.7 MB 10.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 10.7/10.7 MB 8.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy<1.16.0,>=1.8.1 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (1.15.3)\n",
      "Collecting session-info2 (from scanpy)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/db/98/9578ce1d8ae951cf44e6b7434854824f0eae12d54b270e80014f8ab1971c/session_info2-0.1.2-py3-none-any.whl (14 kB)\n",
      "Collecting statsmodels>=0.14.4 (from scanpy)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/05/ac/4276459ea71aa46e2967ea283fc88ee5631c11f29a06787e16cf4aece1b8/statsmodels-0.14.5-cp311-cp311-win_amd64.whl (9.6 MB)\n",
      "     ---------------------------------------- 0.0/9.6 MB ? eta -:--:--\n",
      "     ---------------- ----------------------- 3.9/9.6 MB 26.2 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 3.9/9.6 MB 26.2 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 3.9/9.6 MB 26.2 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 5.2/9.6 MB 6.0 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 6.8/9.6 MB 7.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  9.4/9.6 MB 7.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 9.6/9.6 MB 7.5 MB/s eta 0:00:00\n",
      "Collecting tqdm (from scanpy)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: typing-extensions in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from scanpy) (4.14.0)\n",
      "Collecting umap-learn>=0.5.6 (from scanpy)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/6b/b1/c24deeda9baf1fd491aaad941ed89e0fed6c583a117fd7b79e0a33a1e6c0/umap_learn-0.5.9.post2-py3-none-any.whl (90 kB)\n",
      "Requirement already satisfied: requests in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from gseapy) (2.32.4)\n",
      "Collecting torch>=1.12 (from harmony-pytorch)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/50/9e/acf04ff375b0b49a45511c55d188bcea5c942da2aaf293096676110086d1/torch-2.7.1-cp311-cp311-win_amd64.whl (216.1 MB)\n",
      "     ---------------------------------------- 0.0/216.1 MB ? eta -:--:--\n",
      "      -------------------------------------- 3.9/216.1 MB 23.5 MB/s eta 0:00:10\n",
      "      -------------------------------------- 4.5/216.1 MB 10.3 MB/s eta 0:00:21\n",
      "     - ------------------------------------- 7.3/216.1 MB 13.7 MB/s eta 0:00:16\n",
      "     - ------------------------------------- 9.7/216.1 MB 11.2 MB/s eta 0:00:19\n",
      "     - ------------------------------------ 10.5/216.1 MB 11.7 MB/s eta 0:00:18\n",
      "     -- ----------------------------------- 13.4/216.1 MB 10.6 MB/s eta 0:00:20\n",
      "     -- ------------------------------------ 13.9/216.1 MB 9.2 MB/s eta 0:00:23\n",
      "     -- ----------------------------------- 16.3/216.1 MB 10.1 MB/s eta 0:00:20\n",
      "     --- ----------------------------------- 17.8/216.1 MB 9.4 MB/s eta 0:00:21\n",
      "     --- ---------------------------------- 20.2/216.1 MB 10.0 MB/s eta 0:00:20\n",
      "     --- ----------------------------------- 22.0/216.1 MB 9.5 MB/s eta 0:00:21\n",
      "     ---- ---------------------------------- 23.3/216.1 MB 9.8 MB/s eta 0:00:20\n",
      "     ---- ---------------------------------- 26.2/216.1 MB 9.7 MB/s eta 0:00:20\n",
      "     ----- --------------------------------- 27.8/216.1 MB 9.4 MB/s eta 0:00:20\n",
      "     ----- --------------------------------- 29.4/216.1 MB 9.7 MB/s eta 0:00:20\n",
      "     ----- --------------------------------- 30.4/216.1 MB 9.3 MB/s eta 0:00:21\n",
      "     ----- --------------------------------- 30.4/216.1 MB 9.3 MB/s eta 0:00:21\n",
      "     ------ -------------------------------- 34.1/216.1 MB 9.2 MB/s eta 0:00:20\n",
      "     ------ -------------------------------- 35.4/216.1 MB 8.8 MB/s eta 0:00:21\n",
      "     ------ -------------------------------- 37.5/216.1 MB 9.1 MB/s eta 0:00:20\n",
      "     ------- ------------------------------- 39.3/216.1 MB 8.9 MB/s eta 0:00:20\n",
      "     ------- ------------------------------- 41.2/216.1 MB 9.2 MB/s eta 0:00:20\n",
      "     ------- ------------------------------- 41.4/216.1 MB 8.8 MB/s eta 0:00:20\n",
      "     ------- ------------------------------- 42.2/216.1 MB 8.3 MB/s eta 0:00:21\n",
      "     -------- ------------------------------ 44.6/216.1 MB 8.7 MB/s eta 0:00:20\n",
      "     -------- ------------------------------ 47.4/216.1 MB 8.7 MB/s eta 0:00:20\n",
      "     -------- ------------------------------ 47.4/216.1 MB 8.7 MB/s eta 0:00:20\n",
      "     --------- ----------------------------- 50.3/216.1 MB 8.6 MB/s eta 0:00:20\n",
      "     --------- ----------------------------- 50.3/216.1 MB 8.6 MB/s eta 0:00:20\n",
      "     --------- ----------------------------- 54.5/216.1 MB 8.7 MB/s eta 0:00:19\n",
      "     --------- ----------------------------- 55.3/216.1 MB 8.4 MB/s eta 0:00:20\n",
      "     ---------- ---------------------------- 57.7/216.1 MB 8.7 MB/s eta 0:00:19\n",
      "     ---------- ---------------------------- 60.6/216.1 MB 8.7 MB/s eta 0:00:18\n",
      "     ---------- ---------------------------- 60.8/216.1 MB 8.7 MB/s eta 0:00:18\n",
      "     ----------- --------------------------- 64.0/216.1 MB 8.7 MB/s eta 0:00:18\n",
      "     ----------- --------------------------- 65.5/216.1 MB 8.6 MB/s eta 0:00:18\n",
      "     ------------ -------------------------- 66.8/216.1 MB 8.7 MB/s eta 0:00:18\n",
      "     ------------ -------------------------- 69.2/216.1 MB 8.7 MB/s eta 0:00:17\n",
      "     ------------ -------------------------- 69.2/216.1 MB 8.7 MB/s eta 0:00:17\n",
      "     ------------ -------------------------- 71.0/216.1 MB 8.5 MB/s eta 0:00:18\n",
      "     ------------ -------------------------- 71.8/216.1 MB 8.3 MB/s eta 0:00:18\n",
      "     ------------- ------------------------- 75.0/216.1 MB 8.5 MB/s eta 0:00:17\n",
      "     ------------- ------------------------- 77.3/216.1 MB 8.5 MB/s eta 0:00:17\n",
      "     -------------- ------------------------ 78.4/216.1 MB 8.6 MB/s eta 0:00:17\n",
      "     -------------- ------------------------ 82.3/216.1 MB 8.6 MB/s eta 0:00:16\n",
      "     -------------- ------------------------ 82.3/216.1 MB 8.6 MB/s eta 0:00:16\n",
      "     --------------- ----------------------- 85.5/216.1 MB 8.7 MB/s eta 0:00:16\n",
      "     --------------- ----------------------- 87.3/216.1 MB 8.6 MB/s eta 0:00:16\n",
      "     --------------- ----------------------- 88.3/216.1 MB 8.6 MB/s eta 0:00:15\n",
      "     ---------------- ---------------------- 91.8/216.1 MB 8.7 MB/s eta 0:00:15\n",
      "     ---------------- ---------------------- 91.8/216.1 MB 8.7 MB/s eta 0:00:15\n",
      "     ---------------- ---------------------- 91.8/216.1 MB 8.7 MB/s eta 0:00:15\n",
      "     ---------------- ---------------------- 91.8/216.1 MB 8.7 MB/s eta 0:00:15\n",
      "     ---------------- ---------------------- 92.3/216.1 MB 8.1 MB/s eta 0:00:16\n",
      "     ----------------- --------------------- 94.4/216.1 MB 8.2 MB/s eta 0:00:15\n",
      "     ----------------- --------------------- 97.3/216.1 MB 8.2 MB/s eta 0:00:15\n",
      "     ----------------- --------------------- 98.6/216.1 MB 8.3 MB/s eta 0:00:15\n",
      "     ----------------- -------------------- 102.0/216.1 MB 8.3 MB/s eta 0:00:14\n",
      "     ------------------ ------------------- 102.8/216.1 MB 8.3 MB/s eta 0:00:14\n",
      "     ------------------ ------------------- 106.4/216.1 MB 8.4 MB/s eta 0:00:14\n",
      "     ------------------ ------------------- 107.5/216.1 MB 8.3 MB/s eta 0:00:14\n",
      "     ------------------- ------------------ 109.8/216.1 MB 8.4 MB/s eta 0:00:13\n",
      "     ------------------- ------------------ 111.4/216.1 MB 8.4 MB/s eta 0:00:13\n",
      "     ------------------- ------------------ 113.0/216.1 MB 8.4 MB/s eta 0:00:13\n",
      "     -------------------- ----------------- 115.6/216.1 MB 8.4 MB/s eta 0:00:12\n",
      "     -------------------- ----------------- 117.2/216.1 MB 8.4 MB/s eta 0:00:12\n",
      "     -------------------- ----------------- 118.8/216.1 MB 8.4 MB/s eta 0:00:12\n",
      "     --------------------- ---------------- 121.4/216.1 MB 8.4 MB/s eta 0:00:12\n",
      "     --------------------- ---------------- 122.4/216.1 MB 8.4 MB/s eta 0:00:12\n",
      "     --------------------- ---------------- 124.8/216.1 MB 8.5 MB/s eta 0:00:11\n",
      "     ---------------------- --------------- 126.4/216.1 MB 8.4 MB/s eta 0:00:11\n",
      "     ---------------------- --------------- 127.9/216.1 MB 8.5 MB/s eta 0:00:11\n",
      "     ----------------------- -------------- 130.8/216.1 MB 8.5 MB/s eta 0:00:11\n",
      "     ----------------------- -------------- 132.1/216.1 MB 8.4 MB/s eta 0:00:10\n",
      "     ----------------------- -------------- 134.0/216.1 MB 8.5 MB/s eta 0:00:10\n",
      "     ------------------------ ------------- 137.1/216.1 MB 8.5 MB/s eta 0:00:10\n",
      "     ------------------------ ------------- 137.6/216.1 MB 8.4 MB/s eta 0:00:10\n",
      "     ------------------------ ------------- 138.1/216.1 MB 8.5 MB/s eta 0:00:10\n",
      "     ------------------------ ------------- 141.0/216.1 MB 8.4 MB/s eta 0:00:09\n",
      "     ------------------------ ------------- 142.1/216.1 MB 8.5 MB/s eta 0:00:09\n",
      "     ------------------------- ------------ 145.2/216.1 MB 8.5 MB/s eta 0:00:09\n",
      "     ------------------------- ------------ 145.2/216.1 MB 8.5 MB/s eta 0:00:09\n",
      "     -------------------------- ----------- 148.1/216.1 MB 8.5 MB/s eta 0:00:09\n",
      "     -------------------------- ----------- 149.7/216.1 MB 8.4 MB/s eta 0:00:08\n",
      "     -------------------------- ----------- 152.3/216.1 MB 8.5 MB/s eta 0:00:08\n",
      "     --------------------------- ---------- 153.6/216.1 MB 8.4 MB/s eta 0:00:08\n",
      "     --------------------------- ---------- 155.5/216.1 MB 8.5 MB/s eta 0:00:08\n",
      "     --------------------------- ---------- 155.5/216.1 MB 8.5 MB/s eta 0:00:08\n",
      "     ---------------------------- --------- 159.6/216.1 MB 8.5 MB/s eta 0:00:07\n",
      "     ---------------------------- --------- 160.7/216.1 MB 8.4 MB/s eta 0:00:07\n",
      "     ---------------------------- --------- 163.8/216.1 MB 8.5 MB/s eta 0:00:07\n",
      "     ----------------------------- -------- 165.2/216.1 MB 8.5 MB/s eta 0:00:06\n",
      "     ----------------------------- -------- 167.0/216.1 MB 8.5 MB/s eta 0:00:06\n",
      "     ----------------------------- -------- 169.9/216.1 MB 8.5 MB/s eta 0:00:06\n",
      "     ------------------------------ ------- 170.9/216.1 MB 8.5 MB/s eta 0:00:06\n",
      "     ------------------------------ ------- 172.2/216.1 MB 8.5 MB/s eta 0:00:06\n",
      "     ------------------------------ ------- 172.2/216.1 MB 8.5 MB/s eta 0:00:06\n",
      "     ------------------------------ ------- 175.1/216.1 MB 8.5 MB/s eta 0:00:05\n",
      "     ------------------------------- ------ 177.2/216.1 MB 8.5 MB/s eta 0:00:05\n",
      "     ------------------------------- ------ 179.3/216.1 MB 8.5 MB/s eta 0:00:05\n",
      "     -------------------------------- ----- 182.2/216.1 MB 8.5 MB/s eta 0:00:04\n",
      "     -------------------------------- ----- 182.2/216.1 MB 8.5 MB/s eta 0:00:04\n",
      "     -------------------------------- ----- 185.3/216.1 MB 8.5 MB/s eta 0:00:04\n",
      "     -------------------------------- ----- 186.1/216.1 MB 8.5 MB/s eta 0:00:04\n",
      "     --------------------------------- ---- 189.5/216.1 MB 8.6 MB/s eta 0:00:04\n",
      "     --------------------------------- ---- 190.6/216.1 MB 8.5 MB/s eta 0:00:03\n",
      "     --------------------------------- ---- 192.7/216.1 MB 8.6 MB/s eta 0:00:03\n",
      "     ---------------------------------- --- 194.8/216.1 MB 8.5 MB/s eta 0:00:03\n",
      "     ---------------------------------- --- 196.1/216.1 MB 8.6 MB/s eta 0:00:03\n",
      "     ----------------------------------- -- 199.2/216.1 MB 8.6 MB/s eta 0:00:02\n",
      "     ----------------------------------- -- 199.8/216.1 MB 8.5 MB/s eta 0:00:02\n",
      "     ----------------------------------- -- 203.2/216.1 MB 8.6 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 204.7/216.1 MB 8.6 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 206.3/216.1 MB 8.6 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 208.9/216.1 MB 8.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ - 210.2/216.1 MB 8.7 MB/s eta 0:00:01\n",
      "     -------------------------------------  213.4/216.1 MB 8.7 MB/s eta 0:00:01\n",
      "     -------------------------------------  214.2/216.1 MB 8.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  216.0/216.1 MB 8.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- 216.1/216.1 MB 8.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: psutil in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from harmony-pytorch) (5.9.0)\n",
      "Collecting threadpoolctl (from harmony-pytorch)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/32/d5/f9a850d79b0851d1d4ef6456097579a9005b31fea68726a4ae5f2d82ddd9/threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Collecting array-api-compat!=1.5,>1.4 (from anndata>=0.8->scanpy)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e0/b1/0542e0cab6f49f151a2d7a42400f84f706fc0b64e85dc1f56708b2e9fd37/array_api_compat-1.12.0-py3-none-any.whl (58 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.57.1->scanpy)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/5f/c6/258801143975a6d09a373f2641237992496e15567b907a4d401839d671b8/llvmlite-0.44.0-cp311-cp311-win_amd64.whl (30.3 MB)\n",
      "     ---------------------------------------- 0.0/30.3 MB ? eta -:--:--\n",
      "     ----- ---------------------------------- 3.9/30.3 MB 21.3 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 3.9/30.3 MB 21.3 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 6.3/30.3 MB 9.9 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 8.1/30.3 MB 11.2 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 10.2/30.3 MB 9.8 MB/s eta 0:00:03\n",
      "     -------------- ------------------------ 11.3/30.3 MB 10.4 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 12.8/30.3 MB 8.8 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 15.5/30.3 MB 9.7 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 17.0/30.3 MB 9.1 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 19.4/30.3 MB 9.8 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 21.2/30.3 MB 9.3 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 22.5/30.3 MB 9.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 25.7/30.3 MB 9.6 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 26.5/30.3 MB 9.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 28.8/30.3 MB 9.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 30.3/30.3 MB 9.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Collecting filelock (from torch>=1.12->harmony-pytorch)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/4d/36/2a115987e2d8c300a974597416d9de88f2444426de9571f4b59b2cca3acc/filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.12->harmony-pytorch)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a2/09/77d55d46fd61b4a135c444fc97158ef34a095e5681d0a6c10b75bf356191/sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "     ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "     ------------------------ --------------- 3.9/6.3 MB 18.1 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 4.2/6.3 MB 9.7 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 4.2/6.3 MB 9.7 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 4.7/6.3 MB 6.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 5.5/6.3 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 6.0/6.3 MB 5.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 6.3/6.3 MB 4.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from torch>=1.12->harmony-pytorch) (3.1.6)\n",
      "Collecting fsspec (from torch>=1.12->harmony-pytorch)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/bb/61/78c7b3851add1481b048b5fdc29067397a1784e2910592bc81bb3f608635/fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.12->harmony-pytorch)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/43/e3/7d92a15f894aa0c9c4b49b8ee9ac9850d6e63b03c9c32c0367a13ae62209/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "     -------------------------------------- 536.2/536.2 kB 8.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from jinja2->torch>=1.12->harmony-pytorch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from requests->gseapy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from requests->gseapy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from requests->gseapy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from requests->gseapy) (2025.4.26)\n",
      "Requirement already satisfied: colorama in f:\\githubclone\\brm_mitacs\\.conda\\lib\\site-packages (from tqdm->scanpy) (0.4.6)\n",
      "Installing collected packages: mpmath, tqdm, threadpoolctl, sympy, session-info2, scikit-misc, patsy, networkx, natsort, llvmlite, legacy-api-wrap, joblib, h5py, fsspec, filelock, array-api-compat, torch, scikit-learn, numba, statsmodels, pynndescent, harmony-pytorch, anndata, umap-learn, scanpy\n",
      "\n",
      "   ----------------------------------------  0/25 [mpmath]\n",
      "   ----------------------------------------  0/25 [mpmath]\n",
      "   ----------------------------------------  0/25 [mpmath]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   ---- -----------------------------------  3/25 [sympy]\n",
      "   --------- ------------------------------  6/25 [patsy]\n",
      "   --------- ------------------------------  6/25 [patsy]\n",
      "   ----------- ----------------------------  7/25 [networkx]\n",
      "   ----------- ----------------------------  7/25 [networkx]\n",
      "   ----------- ----------------------------  7/25 [networkx]\n",
      "   ----------- ----------------------------  7/25 [networkx]\n",
      "   ----------- ----------------------------  7/25 [networkx]\n",
      "   ----------- ----------------------------  7/25 [networkx]\n",
      "   ----------- ----------------------------  7/25 [networkx]\n",
      "   ----------- ----------------------------  7/25 [networkx]\n",
      "   ----------- ----------------------------  7/25 [networkx]\n",
      "   ----------- ----------------------------  7/25 [networkx]\n",
      "   ----------- ----------------------------  7/25 [networkx]\n",
      "   ----------- ----------------------------  7/25 [networkx]\n",
      "   ----------- ----------------------------  7/25 [networkx]\n",
      "   -------------- -------------------------  9/25 [llvmlite]\n",
      "   -------------- -------------------------  9/25 [llvmlite]\n",
      "   -------------- -------------------------  9/25 [llvmlite]\n",
      "   ----------------- ---------------------- 11/25 [joblib]\n",
      "   ----------------- ---------------------- 11/25 [joblib]\n",
      "   ------------------- -------------------- 12/25 [h5py]\n",
      "   ------------------- -------------------- 12/25 [h5py]\n",
      "   -------------------- ------------------- 13/25 [fsspec]\n",
      "   ------------------------ --------------- 15/25 [array-api-compat]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   ------------------------- -------------- 16/25 [torch]\n",
      "   --------------------------- ------------ 17/25 [scikit-learn]\n",
      "   --------------------------- ------------ 17/25 [scikit-learn]\n",
      "   --------------------------- ------------ 17/25 [scikit-learn]\n",
      "   --------------------------- ------------ 17/25 [scikit-learn]\n",
      "   --------------------------- ------------ 17/25 [scikit-learn]\n",
      "   --------------------------- ------------ 17/25 [scikit-learn]\n",
      "   --------------------------- ------------ 17/25 [scikit-learn]\n",
      "   --------------------------- ------------ 17/25 [scikit-learn]\n",
      "   --------------------------- ------------ 17/25 [scikit-learn]\n",
      "   --------------------------- ------------ 17/25 [scikit-learn]\n",
      "   --------------------------- ------------ 17/25 [scikit-learn]\n",
      "   --------------------------- ------------ 17/25 [scikit-learn]\n",
      "   --------------------------- ------------ 17/25 [scikit-learn]\n",
      "   --------------------------- ------------ 17/25 [scikit-learn]\n",
      "   --------------------------- ------------ 17/25 [scikit-learn]\n",
      "   --------------------------- ------------ 17/25 [scikit-learn]\n",
      "   --------------------------- ------------ 17/25 [scikit-learn]\n",
      "   --------------------------- ------------ 17/25 [scikit-learn]\n",
      "   --------------------------- ------------ 17/25 [scikit-learn]\n",
      "   --------------------------- ------------ 17/25 [scikit-learn]\n",
      "   ---------------------------- ----------- 18/25 [numba]\n",
      "   ---------------------------- ----------- 18/25 [numba]\n",
      "   ---------------------------- ----------- 18/25 [numba]\n",
      "   ---------------------------- ----------- 18/25 [numba]\n",
      "   ---------------------------- ----------- 18/25 [numba]\n",
      "   ---------------------------- ----------- 18/25 [numba]\n",
      "   ---------------------------- ----------- 18/25 [numba]\n",
      "   ---------------------------- ----------- 18/25 [numba]\n",
      "   ---------------------------- ----------- 18/25 [numba]\n",
      "   ---------------------------- ----------- 18/25 [numba]\n",
      "   ---------------------------- ----------- 18/25 [numba]\n",
      "   ---------------------------- ----------- 18/25 [numba]\n",
      "   ---------------------------- ----------- 18/25 [numba]\n",
      "   ---------------------------- ----------- 18/25 [numba]\n",
      "   ---------------------------- ----------- 18/25 [numba]\n",
      "   ---------------------------- ----------- 18/25 [numba]\n",
      "   ---------------------------- ----------- 18/25 [numba]\n",
      "   ---------------------------- ----------- 18/25 [numba]\n",
      "   ---------------------------- ----------- 18/25 [numba]\n",
      "   ---------------------------- ----------- 18/25 [numba]\n",
      "   ---------------------------- ----------- 18/25 [numba]\n",
      "   ---------------------------- ----------- 18/25 [numba]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   ------------------------------ --------- 19/25 [statsmodels]\n",
      "   -------------------------------- ------- 20/25 [pynndescent]\n",
      "   ----------------------------------- ---- 22/25 [anndata]\n",
      "   ------------------------------------ --- 23/25 [umap-learn]\n",
      "   -------------------------------------- - 24/25 [scanpy]\n",
      "   -------------------------------------- - 24/25 [scanpy]\n",
      "   -------------------------------------- - 24/25 [scanpy]\n",
      "   ---------------------------------------- 25/25 [scanpy]\n",
      "\n",
      "Successfully installed anndata-0.11.4 array-api-compat-1.12.0 filelock-3.18.0 fsspec-2025.5.1 h5py-3.14.0 harmony-pytorch-0.1.8 joblib-1.5.1 legacy-api-wrap-1.4.1 llvmlite-0.44.0 mpmath-1.3.0 natsort-8.4.0 networkx-3.5 numba-0.61.2 patsy-1.0.1 pynndescent-0.5.13 scanpy-1.11.3 scikit-learn-1.7.0 scikit-misc-0.5.1 session-info2-0.1.2 statsmodels-0.14.5 sympy-1.14.0 threadpoolctl-3.6.0 torch-2.7.1 tqdm-4.67.1 umap-learn-0.5.9.post2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 如果您使用的是conda环境，建议先用conda安装一些基础包\n",
    "# conda install -c conda-forge scanpy python-igraph leidenalg\n",
    "\n",
    "# 然后使用pip安装其他包\n",
    "%pip install scanpy gseapy scikit-misc harmony-pytorch pandas matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baf29f7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 导入所有需要的库\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置Scanpy的绘图参数，使其更美观\n",
    "sc.settings.verbosity = 3  # 设置日志信息的详细程度\n",
    "sc.logging.print_header()\n",
    "sc.settings.set_figure_params(dpi=80, facecolor='white')\n",
    "\n",
    "# 设置中文字体支持\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"环境设置完成！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db718dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所有需要的库\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置Scanpy的绘图参数，使其更美观\n",
    "sc.settings.verbosity = 3  # 设置日志信息的详细程度\n",
    "sc.logging.print_header()\n",
    "sc.settings.set_figure_params(dpi=80, facecolor='white')\n",
    "\n",
    "# 设置中文字体支持\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"环境设置完成！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c867f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所有需要的库\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置Scanpy的绘图参数，使其更美观\n",
    "sc.settings.verbosity = 3  # 设置日志信息的详细程度\n",
    "sc.logging.print_header()\n",
    "sc.settings.set_figure_params(dpi=80, facecolor='white')\n",
    "\n",
    "# 设置中文字体支持\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"环境设置完成！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4c6076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所有需要的库\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置Scanpy的绘图参数，使其更美观\n",
    "sc.settings.verbosity = 3  # 设置日志信息的详细程度\n",
    "sc.logging.print_header()\n",
    "sc.settings.set_figure_params(dpi=80, facecolor='white')\n",
    "\n",
    "# 设置中文字体支持\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"环境设置完成！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0f0f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所有需要的库\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置Scanpy的绘图参数，使其更美观\n",
    "sc.settings.verbosity = 3  # 设置日志信息的详细程度\n",
    "sc.logging.print_header()\n",
    "sc.settings.set_figure_params(dpi=80, facecolor='white')\n",
    "\n",
    "# 设置中文字体支持\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"环境设置完成！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a216be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所有需要的库\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置Scanpy的绘图参数，使其更美观\n",
    "sc.settings.verbosity = 3  # 设置日志信息的详细程度\n",
    "sc.logging.print_header()\n",
    "sc.settings.set_figure_params(dpi=80, facecolor='white')\n",
    "\n",
    "# 设置中文字体支持\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"环境设置完成！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b2a9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所有需要的库\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置Scanpy的绘图参数，使其更美观\n",
    "sc.settings.verbosity = 3  # 设置日志信息的详细程度\n",
    "sc.logging.print_header()\n",
    "sc.settings.set_figure_params(dpi=80, facecolor='white')\n",
    "\n",
    "# 设置中文字体支持\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"环境设置完成！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7f2ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所有需要的库\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置Scanpy的绘图参数，使其更美观\n",
    "sc.settings.verbosity = 3  # 设置日志信息的详细程度\n",
    "sc.logging.print_header()\n",
    "sc.settings.set_figure_params(dpi=80, facecolor='white')\n",
    "\n",
    "# 设置中文字体支持\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"环境设置完成！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8050aa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所有需要的库\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置Scanpy的绘图参数，使其更美观\n",
    "sc.settings.verbosity = 3  # 设置日志信息的详细程度\n",
    "sc.logging.print_header()\n",
    "sc.settings.set_figure_params(dpi=80, facecolor='white')\n",
    "\n",
    "# 设置中文字体支持\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"环境设置完成！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a1b9b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 导入所有需要的库\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置Scanpy的绘图参数，使其更美观\n",
    "sc.settings.verbosity = 3  # 设置日志信息的详细程度\n",
    "sc.logging.print_header()\n",
    "sc.settings.set_figure_params(dpi=80, facecolor='white')\n",
    "\n",
    "# 设置中文字体支持\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"环境设置完成！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e77cdf",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 导入所有需要的库\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置Scanpy的绘图参数，使其更美观\n",
    "sc.settings.verbosity = 3  # 设置日志信息的详细程度\n",
    "sc.logging.print_header()\n",
    "sc.settings.set_figure_params(dpi=80, facecolor='white')\n",
    "\n",
    "# 设置中文字体支持\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"环境设置完成！\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## 步骤一：数据加载、预处理与质量控制 (QC)\n",
    "\n",
    "分析的第一步是加载原始数据，并进行严格的质量控制，过滤掉低质量的细胞和基因，确保后续分析的准确性。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159526f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 数据加载 ---\n",
    "\n",
    "# 定义文件路径 (请根据您的项目结构调整)\n",
    "# 假设Notebook在 `notebooks/` 目录下，数据在 `data/raw/singlecell/`\n",
    "counts_path = '../data/raw/singlecell/UMIcounts_HGSC.tsv'\n",
    "annotation_path = '../data/raw/singlecell/annotation_HGSC.tsv'\n",
    "output_dir = '../results/single_cell_analysis/'\n",
    "\n",
    "# 创建输出目录\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "print(f\"数据路径:\")\n",
    "print(f\"  UMI计数文件: {counts_path}\")\n",
    "print(f\"  注释文件: {annotation_path}\")\n",
    "print(f\"  输出目录: {output_dir}\")\n",
    "\n",
    "# 检查文件是否存在\n",
    "if os.path.exists(counts_path):\n",
    "    print(\"✓ UMI计数文件存在\")\n",
    "else:\n",
    "    print(\"✗ UMI计数文件不存在，请检查路径\")\n",
    "    \n",
    "if os.path.exists(annotation_path):\n",
    "    print(\"✓ 注释文件存在\")\n",
    "else:\n",
    "    print(\"✗ 注释文件不存在，请检查路径\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef460ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取UMI计数矩阵\n",
    "print(\"正在读取UMI计数矩阵...\")\n",
    "counts_df = pd.read_csv(counts_path, sep='\\t', index_col=0)\n",
    "print(f\"原始计数矩阵形状: {counts_df.shape} (基因 x 细胞)\")\n",
    "\n",
    "# 转置为Scanpy要求的 细胞x基因 格式\n",
    "adata = sc.AnnData(counts_df.T)\n",
    "print(f\"AnnData对象形状: {adata.shape} (细胞 x 基因)\")\n",
    "\n",
    "# 读取并加载细胞注释信息\n",
    "print(\"\\n正在读取细胞注释信息...\")\n",
    "annotation_df = pd.read_csv(annotation_path, sep='\\t', index_col=0)\n",
    "print(f\"注释信息形状: {annotation_df.shape}\")\n",
    "print(f\"注释列名: {list(annotation_df.columns)}\")\n",
    "\n",
    "# 将注释信息合并到AnnData对象中\n",
    "adata.obs = adata.obs.join(annotation_df)\n",
    "\n",
    "print(\"\\nAnnData对象创建成功:\")\n",
    "print(adata)\n",
    "\n",
    "# 显示前几行注释信息\n",
    "print(\"\\n前5个细胞的注释信息:\")\n",
    "print(adata.obs.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdc9216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 质量控制 (QC) ---\n",
    "\n",
    "# 识别线粒体基因 (通常以 'MT-' 开头)\n",
    "adata.var['mt'] = adata.var_names.str.startswith('MT-')\n",
    "print(f\"识别出 {adata.var['mt'].sum()} 个线粒体基因\")\n",
    "\n",
    "# 识别核糖体基因 (通常以 'RPS' 或 'RPL' 开头)\n",
    "adata.var['ribo'] = adata.var_names.str.startswith(('RPS', 'RPL'))\n",
    "print(f\"识别出 {adata.var['ribo'].sum()} 个核糖体基因\")\n",
    "\n",
    "# 计算QC指标\n",
    "sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True)\n",
    "sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
    "sc.pp.calculate_qc_metrics(adata, qc_vars=['ribo'], percent_top=None, log1p=False, inplace=True)\n",
    "\n",
    "print(\"\\n质量控制指标计算完成\")\n",
    "print(f\"QC指标列: {[col for col in adata.obs.columns if 'qc' in col.lower() or 'count' in col or 'gene' in col]}\")\n",
    "\n",
    "# 显示QC统计信息\n",
    "print(\"\\n基本QC统计:\")\n",
    "print(f\"细胞数: {adata.n_obs}\")\n",
    "print(f\"基因数: {adata.n_vars}\")\n",
    "print(f\"每个细胞平均基因数: {adata.obs['n_genes_by_counts'].mean():.1f}\")\n",
    "print(f\"每个细胞平均UMI数: {adata.obs['total_counts'].mean():.1f}\")\n",
    "print(f\"平均线粒体基因比例: {adata.obs['pct_counts_mt'].mean():.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7802a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化QC指标，帮助确定过滤阈值\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# 基因数分布\n",
    "axes[0].hist(adata.obs['n_genes_by_counts'], bins=50, alpha=0.7)\n",
    "axes[0].set_xlabel('检测到的基因数')\n",
    "axes[0].set_ylabel('细胞数')\n",
    "axes[0].set_title('每个细胞检测到的基因数分布')\n",
    "axes[0].axvline(x=200, color='red', linestyle='--', label='最小阈值=200')\n",
    "axes[0].axvline(x=5000, color='red', linestyle='--', label='最大阈值=5000')\n",
    "axes[0].legend()\n",
    "\n",
    "# UMI数分布\n",
    "axes[1].hist(adata.obs['total_counts'], bins=50, alpha=0.7)\n",
    "axes[1].set_xlabel('总UMI数')\n",
    "axes[1].set_ylabel('细胞数')\n",
    "axes[1].set_title('每个细胞总UMI数分布')\n",
    "axes[1].axvline(x=1000, color='red', linestyle='--', label='最小阈值=1000')\n",
    "axes[1].legend()\n",
    "\n",
    "# 线粒体基因比例分布\n",
    "axes[2].hist(adata.obs['pct_counts_mt'], bins=50, alpha=0.7)\n",
    "axes[2].set_xlabel('线粒体基因比例 (%)')\n",
    "axes[2].set_ylabel('细胞数')\n",
    "axes[2].set_title('线粒体基因比例分布')\n",
    "axes[2].axvline(x=20, color='red', linestyle='--', label='最大阈值=20%')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'qc_metrics_before_filtering.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"QC指标可视化完成，请根据分布情况调整过滤阈值\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3ebabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据QC指标进行过滤\n",
    "print(\"过滤前统计:\")\n",
    "print(f\"细胞数: {adata.n_obs}\")\n",
    "print(f\"基因数: {adata.n_vars}\")\n",
    "\n",
    "# 过滤低质量细胞和基因\n",
    "sc.pp.filter_cells(adata, min_genes=200)  # 过滤掉基因数少于200的细胞\n",
    "sc.pp.filter_genes(adata, min_cells=3)    # 过滤掉在少于3个细胞中表达的基因\n",
    "\n",
    "# 过滤线粒体基因比例过高的细胞\n",
    "adata = adata[adata.obs.pct_counts_mt < 20, :]\n",
    "\n",
    "# 过滤基因数过多的细胞（可能是双细胞）\n",
    "adata = adata[adata.obs.n_genes_by_counts < 5000, :]\n",
    "\n",
    "# 过滤UMI数过低的细胞\n",
    "adata = adata[adata.obs.total_counts > 1000, :]\n",
    "\n",
    "print(\"\\n过滤后统计:\")\n",
    "print(f\"细胞数: {adata.n_obs}\")\n",
    "print(f\"基因数: {adata.n_vars}\")\n",
    "\n",
    "# 显示各组样本的细胞数\n",
    "print(\"\\n各组样本的细胞数:\")\n",
    "print(adata.obs.groupby(['Sample', 'Type']).size())\n",
    "\n",
    "print(\"\\n质量控制和过滤完成！\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## 步骤二：数据整合、降维与聚类\n",
    "\n",
    "完成QC后，我们需要对数据进行标准化，并处理来自不同样本/测序批次的批次效应。然后，通过降维和聚类，识别出具有相似表达模式的细胞群。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bb450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 数据标准化与特征选择 ---\n",
    "\n",
    "# 对每个细胞的总计数进行标准化，然后进行log1p对数变换\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "print(\"数据标准化完成\")\n",
    "\n",
    "# 识别高变异基因 (Highly Variable Genes, HVGs)\n",
    "sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "\n",
    "print(f\"识别出 {adata.var.highly_variable.sum()} 个高变异基因\")\n",
    "\n",
    "# 可视化高变异基因\n",
    "sc.pl.highly_variable_genes(adata, save='_highly_variable_genes.png')\n",
    "\n",
    "# 保存原始（标准化后）的表达数据\n",
    "adata.raw = adata\n",
    "\n",
    "# 只保留高变异基因进行后续分析\n",
    "adata = adata[:, adata.var.highly_variable]\n",
    "\n",
    "print(f\"保留 {adata.n_vars} 个高变异基因进行后续分析\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b5914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 批次效应校正 ---\n",
    "\n",
    "# 首先进行PCA降维\n",
    "sc.pp.scale(adata, max_value=10)  # 对基因进行缩放，使均值为0，方差为1\n",
    "sc.tl.pca(adata, svd_solver='arpack')\n",
    "\n",
    "print(\"PCA降维完成\")\n",
    "\n",
    "# 可视化PCA，检查是否存在批次效应\n",
    "sc.pl.pca_variance_ratio(adata, log=True, n_pcs=50, save='_pca_variance.png')\n",
    "\n",
    "# 检查不同样本在PCA空间中的分布\n",
    "sc.pl.pca(adata, color='Sample', save='_pca_by_sample.png')\n",
    "sc.pl.pca(adata, color='Type', save='_pca_by_type.png')\n",
    "\n",
    "print(\"PCA可视化完成，请检查是否存在明显的批次效应\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5765afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尝试使用Harmony进行批次校正\n",
    "try:\n",
    "    import harmonypy as hm\n",
    "    \n",
    "    # 使用Harmony进行批次校正\n",
    "    harmony_out = hm.run_harmony(adata.obsm['X_pca'], adata.obs, vars_use=['Sample'])\n",
    "    adata.obsm['X_pca_harmony'] = harmony_out.Z_corr.T\n",
    "    \n",
    "    print(\"Harmony批次校正完成\")\n",
    "    \n",
    "    # 可视化校正后的结果\n",
    "    sc.pl.embedding(adata, basis='X_pca_harmony', color='Sample', save='_harmony_by_sample.png')\n",
    "    sc.pl.embedding(adata, basis='X_pca_harmony', color='Type', save='_harmony_by_type.png')\n",
    "    \n",
    "    use_harmony = True\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"Harmony未安装，跳过批次校正\")\n",
    "    print(\"如需使用Harmony，请安装: pip install harmonypy\")\n",
    "    use_harmony = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d80b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 降维与聚类 ---\n",
    "\n",
    "# 选择用于邻近图计算的表示\n",
    "if use_harmony:\n",
    "    rep_key = 'X_pca_harmony'\n",
    "    print(\"使用Harmony校正后的PCA进行后续分析\")\n",
    "else:\n",
    "    rep_key = 'X_pca'\n",
    "    print(\"使用原始PCA进行后续分析\")\n",
    "\n",
    "# 计算邻近图\n",
    "sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, use_rep=rep_key)\n",
    "\n",
    "# 使用Leiden算法进行细胞聚类\n",
    "sc.tl.leiden(adata, resolution=0.5)  # resolution参数可以调整聚类的精细程度\n",
    "\n",
    "print(f\"Leiden聚类完成，共识别出 {len(adata.obs['leiden'].unique())} 个聚类\")\n",
    "\n",
    "# 进行UMAP非线性降维，用于可视化\n",
    "sc.tl.umap(adata)\n",
    "\n",
    "print(\"UMAP降维完成\")\n",
    "\n",
    "# 可视化聚类结果\n",
    "sc.pl.umap(adata, color=['leiden', 'Sample', 'Type'], \n",
    "           save='_umap_overview.png', ncols=3)\n",
    "\n",
    "print(\"聚类和降维分析完成！\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## 步骤三：细胞类型鉴定与注释\n",
    "\n",
    "这一步的目标是为上一步得到的每个细胞聚类（cluster）赋予生物学身份，例如\"癌细胞\"、\"T细胞\"等。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4987055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 寻找标记基因 (Marker Genes) ---\n",
    "\n",
    "# 计算每个聚类的标记基因\n",
    "sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon')\n",
    "\n",
    "print(\"标记基因计算完成\")\n",
    "\n",
    "# 可视化Top标记基因\n",
    "sc.pl.rank_genes_groups(adata, n_genes=5, sharey=False, save='_marker_genes_heatmap.png')\n",
    "\n",
    "# 可视化标记基因的表达热图\n",
    "sc.pl.rank_genes_groups_heatmap(adata, n_genes=3, save='_marker_genes_expression_heatmap.png')\n",
    "\n",
    "print(\"标记基因可视化完成\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bd46b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 基于已知标记进行细胞注释 ---\n",
    "\n",
    "# 定义经典的细胞类型标记基因\n",
    "marker_genes = {\n",
    "    'Cancer_Cells': ['EPCAM', 'PAX8', 'KRT7', 'MUC16', 'WT1'],\n",
    "    'T_Cells': ['CD3D', 'CD3E', 'CD8A', 'CD4', 'IL7R'],\n",
    "    'B_Cells': ['MS4A1', 'CD19', 'CD79A', 'CD79B'],\n",
    "    'Myeloid_Cells': ['CD68', 'CD14', 'CD163', 'C1QA', 'LYZ'],\n",
    "    'Fibroblasts': ['DCN', 'COL1A1', 'COL3A1', 'LUM', 'VIM'],\n",
    "    'Endothelial_Cells': ['PECAM1', 'VWF', 'CDH5', 'ENG'],\n",
    "    'NK_Cells': ['GNLY', 'NKG7', 'PRF1', 'GZMB'],\n",
    "    'Dendritic_Cells': ['FCER1A', 'CD1C', 'CLEC9A']\n",
    "}\n",
    "\n",
    "# 检查这些标记基因是否在数据中存在\n",
    "print(\"检查标记基因可用性:\")\n",
    "for cell_type, genes in marker_genes.items():\n",
    "    available_genes = [g for g in genes if g in adata.raw.var_names]\n",
    "    print(f\"{cell_type}: {len(available_genes)}/{len(genes)} 个基因可用\")\n",
    "    if available_genes:\n",
    "        print(f\"  可用基因: {', '.join(available_genes)}\")\n",
    "\n",
    "# 筛选出实际存在的标记基因\n",
    "filtered_marker_genes = {}\n",
    "for cell_type, genes in marker_genes.items():\n",
    "    available_genes = [g for g in genes if g in adata.raw.var_names]\n",
    "    if available_genes:\n",
    "        filtered_marker_genes[cell_type] = available_genes\n",
    "\n",
    "print(f\"\\n最终用于注释的细胞类型数: {len(filtered_marker_genes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37e7353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用点图可视化标记基因在各个聚类中的表达情况\n",
    "if filtered_marker_genes:\n",
    "    sc.pl.dotplot(adata, filtered_marker_genes, groupby='leiden', \n",
    "                  save='_marker_gene_dotplot.png', use_raw=True)\n",
    "    \n",
    "    # 在UMAP上可视化一些关键标记基因\n",
    "    key_markers = ['EPCAM', 'CD3D', 'CD68', 'DCN', 'PECAM1']\n",
    "    available_key_markers = [g for g in key_markers if g in adata.raw.var_names]\n",
    "    \n",
    "    if available_key_markers:\n",
    "        sc.pl.umap(adata, color=available_key_markers, use_raw=True, \n",
    "                   save='_key_markers_umap.png', ncols=3)\n",
    "    \n",
    "    print(\"标记基因表达可视化完成\")\n",
    "else:\n",
    "    print(\"未找到足够的标记基因进行可视化\")\n",
    "\n",
    "# 显示每个聚类的细胞数和在不同组中的分布\n",
    "cluster_stats = adata.obs.groupby(['leiden', 'Type']).size().unstack(fill_value=0)\n",
    "print(\"\\n各聚类在不同组中的细胞数分布:\")\n",
    "print(cluster_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e38252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据标记基因表达和聚类分布进行手动注释\n",
    "# 这需要根据实际的点图和UMAP结果进行调整\n",
    "\n",
    "# 示例注释（需要根据实际结果调整）\n",
    "def annotate_clusters(adata):\n",
    "    \"\"\"\n",
    "    根据标记基因表达模式注释细胞类型\n",
    "    这个函数需要根据实际的可视化结果进行调整\n",
    "    \"\"\"\n",
    "    # 获取每个聚类的标记基因表达得分\n",
    "    cluster_annotations = {}\n",
    "    \n",
    "    for cluster in adata.obs['leiden'].unique():\n",
    "        cluster_cells = adata[adata.obs['leiden'] == cluster]\n",
    "        \n",
    "        # 计算各种细胞类型标记基因的平均表达\n",
    "        scores = {}\n",
    "        for cell_type, genes in filtered_marker_genes.items():\n",
    "            if genes:  # 确保有可用基因\n",
    "                # 计算该细胞类型标记基因的平均表达\n",
    "                expr_data = cluster_cells.raw[:, genes].X\n",
    "                if hasattr(expr_data, 'toarray'):\n",
    "                    expr_data = expr_data.toarray()\n",
    "                scores[cell_type] = np.mean(expr_data)\n",
    "        \n",
    "        # 选择得分最高的细胞类型\n",
    "        if scores:\n",
    "            best_type = max(scores, key=scores.get)\n",
    "            cluster_annotations[cluster] = best_type\n",
    "        else:\n",
    "            cluster_annotations[cluster] = 'Unknown'\n",
    "    \n",
    "    return cluster_annotations\n",
    "\n",
    "# 执行自动注释\n",
    "cluster_annotations = annotate_clusters(adata)\n",
    "\n",
    "print(\"聚类注释结果:\")\n",
    "for cluster, annotation in cluster_annotations.items():\n",
    "    cell_count = sum(adata.obs['leiden'] == cluster)\n",
    "    print(f\"聚类 {cluster}: {annotation} ({cell_count} 个细胞)\")\n",
    "\n",
    "# 将注释添加到AnnData对象\n",
    "adata.obs['cell_type_auto'] = adata.obs['leiden'].map(cluster_annotations)\n",
    "\n",
    "# 可视化注释结果\n",
    "sc.pl.umap(adata, color='cell_type_auto', legend_loc='on data', \n",
    "           save='_cell_type_annotation.png')\n",
    "\n",
    "print(\"\\n自动细胞类型注释完成！\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## 步骤四：耐药组 vs. 敏感组的差异分析\n",
    "\n",
    "在鉴定出细胞类型后，我们就可以比较耐药组（refractory）和敏感组（sensitive）的差异了，这是本研究的核心。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee931e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 细胞组成差异分析 ---\n",
    "\n",
    "# 计算每种细胞类型在不同样本和分组中的比例\n",
    "composition = adata.obs.groupby(['Type', 'Sample', 'cell_type_auto']).size().unstack(fill_value=0)\n",
    "composition_proportions = composition.div(composition.sum(axis=1), axis=0)\n",
    "\n",
    "print(\"细胞类型组成比例:\")\n",
    "print(composition_proportions)\n",
    "\n",
    "# 计算每种细胞类型在两组中的平均比例\n",
    "group_composition = adata.obs.groupby(['Type', 'cell_type_auto']).size().unstack(fill_value=0)\n",
    "group_proportions = group_composition.div(group_composition.sum(axis=1), axis=0)\n",
    "\n",
    "print(\"\\n各组细胞类型平均比例:\")\n",
    "print(group_proportions)\n",
    "\n",
    "# 可视化细胞组成差异\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# 按样本显示\n",
    "composition_proportions.plot(kind='bar', stacked=True, ax=axes[0])\n",
    "axes[0].set_title('各样本细胞类型组成')\n",
    "axes[0].set_ylabel('比例')\n",
    "axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# 按组显示\n",
    "group_proportions.plot(kind='bar', ax=axes[1])\n",
    "axes[1].set_title('耐药组 vs 敏感组细胞类型比例')\n",
    "axes[1].set_ylabel('比例')\n",
    "axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[1].set_xticklabels(['耐药组', '敏感组'], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'cell_composition_analysis.png'), \n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"细胞组成差异分析完成\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cc632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 差异表达基因 (DEG) 分析 ---\n",
    "\n",
    "# 重点分析癌细胞中的差异表达基因\n",
    "cancer_cells = adata[adata.obs['cell_type_auto'] == 'Cancer_Cells'].copy()\n",
    "\n",
    "if cancer_cells.n_obs > 0:\n",
    "    print(f\"抽取出 {cancer_cells.n_obs} 个癌细胞用于差异分析\")\n",
    "    \n",
    "    # 检查两组的细胞数\n",
    "    type_counts = cancer_cells.obs['Type'].value_counts()\n",
    "    print(f\"癌细胞分组情况:\")\n",
    "    print(type_counts)\n",
    "    \n",
    "    if len(type_counts) >= 2 and type_counts.min() >= 10:\n",
    "        # 进行差异表达分析\n",
    "        sc.tl.rank_genes_groups(cancer_cells, 'Type', \n",
    "                               groups=['refractory'], \n",
    "                               reference='sensitive', \n",
    "                               method='wilcoxon')\n",
    "        \n",
    "        print(\"癌细胞差异表达分析完成\")\n",
    "        \n",
    "        # 可视化火山图\n",
    "        sc.pl.rank_genes_groups_volcano(cancer_cells, save='_cancer_deg_volcano.png')\n",
    "        \n",
    "        # 获取差异表达基因结果\n",
    "        deg_results = sc.get.rank_genes_groups_df(cancer_cells, group='refractory')\n",
    "        deg_results = deg_results[deg_results['pvals_adj'] < 0.05]  # 只保留显著的基因\n",
    "        \n",
    "        print(f\"\\n显著差异表达基因数量: {len(deg_results)}\")\n",
    "        print(\"Top 10 上调基因:\")\n",
    "        print(deg_results.head(10)[['names', 'logfoldchanges', 'pvals_adj']])\n",
    "        \n",
    "        # 保存差异表达基因结果\n",
    "        deg_results.to_csv(os.path.join(output_dir, 'cancer_cells_deg_results.csv'), index=False)\n",
    "        \n",
    "        # 可视化Top差异基因的表达\n",
    "        top_genes = deg_results.head(10)['names'].tolist()\n",
    "        available_top_genes = [g for g in top_genes if g in cancer_cells.raw.var_names]\n",
    "        \n",
    "        if available_top_genes:\n",
    "            sc.pl.violin(cancer_cells, keys=available_top_genes[:6], \n",
    "                        groupby='Type', use_raw=True, \n",
    "                        save='_top_deg_violin.png')\n",
    "    else:\n",
    "        print(\"癌细胞数量不足，无法进行差异分析\")\n",
    "        deg_results = pd.DataFrame()\n",
    "else:\n",
    "    print(\"未找到癌细胞，跳过差异分析\")\n",
    "    deg_results = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e188efb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 通路富集分析 (GSEA) ---\n",
    "\n",
    "if not deg_results.empty:\n",
    "    try:\n",
    "        import gseapy as gp\n",
    "        \n",
    "        # 准备基因列表进行GSEA\n",
    "        gene_list = deg_results.set_index('names')['logfoldchanges'].sort_values(ascending=False)\n",
    "        \n",
    "        print(f\"用于GSEA的基因数量: {len(gene_list)}\")\n",
    "        \n",
    "        # 运行GSEA\n",
    "        gsea_results = gp.prerank(\n",
    "            rnk=gene_list,\n",
    "            gene_sets=['GO_Biological_Process_2021', 'KEGG_2021_Human'],\n",
    "            threads=4,\n",
    "            min_size=5,\n",
    "            max_size=500,\n",
    "            permutation_num=100,  # 实际分析建议用1000\n",
    "            outdir=os.path.join(output_dir, 'gsea_results'),\n",
    "            seed=42,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        print(\"GSEA分析完成\")\n",
    "        \n",
    "        # 显示Top富集通路\n",
    "        gsea_df = gsea_results.res2d\n",
    "        significant_pathways = gsea_df[gsea_df['FDR q-val'] < 0.05]\n",
    "        \n",
    "        print(f\"\\n显著富集通路数量: {len(significant_pathways)}\")\n",
    "        \n",
    "        if len(significant_pathways) > 0:\n",
    "            print(\"Top 10 富集通路:\")\n",
    "            print(significant_pathways.head(10)[['Term', 'ES', 'NES', 'FDR q-val']])\n",
    "            \n",
    "            # 检查IFN-I和缺氧相关通路\n",
    "            ifn_pathways = significant_pathways[\n",
    "                significant_pathways['Term'].str.contains('interferon|IFN', case=False, na=False)\n",
    "            ]\n",
    "            hypoxia_pathways = significant_pathways[\n",
    "                significant_pathways['Term'].str.contains('hypoxia|oxygen', case=False, na=False)\n",
    "            ]\n",
    "            \n",
    "            print(f\"\\n干扰素相关通路数量: {len(ifn_pathways)}\")\n",
    "            if len(ifn_pathways) > 0:\n",
    "                print(\"干扰素相关通路:\")\n",
    "                print(ifn_pathways[['Term', 'ES', 'NES', 'FDR q-val']])\n",
    "            \n",
    "            print(f\"\\n缺氧相关通路数量: {len(hypoxia_pathways)}\")\n",
    "            if len(hypoxia_pathways) > 0:\n",
    "                print(\"缺氧相关通路:\")\n",
    "                print(hypoxia_pathways[['Term', 'ES', 'NES', 'FDR q-val']])\n",
    "        \n",
    "        # 保存结果\n",
    "        gsea_df.to_csv(os.path.join(output_dir, 'gsea_all_results.csv'), index=False)\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"gseapy未安装，跳过GSEA分析\")\n",
    "        print(\"如需进行通路富集分析，请安装: pip install gseapy\")\n",
    "    except Exception as e:\n",
    "        print(f\"GSEA分析出错: {e}\")\n",
    "else:\n",
    "    print(\"无差异表达基因，跳过GSEA分析\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## 步骤五：聚焦 BRM (SMARCA2) 的深度分析\n",
    "\n",
    "现在，我们将注意力集中到核心目标基因 `SMARCA2` 上。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b31cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SMARCA2 表达可视化 ---\n",
    "\n",
    "# 检查SMARCA2是否在数据中\n",
    "if 'SMARCA2' in adata.raw.var_names:\n",
    "    print(\"✓ SMARCA2基因在数据中存在\")\n",
    "    \n",
    "    # 在UMAP图上可视化 SMARCA2 的表达\n",
    "    sc.pl.umap(adata, color='SMARCA2', use_raw=True, \n",
    "               title='SMARCA2 Expression', save='_smarca2_umap.png')\n",
    "    \n",
    "    # 在不同细胞类型中可视化 SMARCA2 的表达\n",
    "    sc.pl.violin(adata, keys='SMARCA2', groupby='cell_type_auto', \n",
    "                 rotation=90, use_raw=True, save='_smarca2_violin_celltype.png')\n",
    "    \n",
    "    # 在不同分组中可视化 SMARCA2 的表达\n",
    "    sc.pl.violin(adata, keys='SMARCA2', groupby='Type', \n",
    "                 use_raw=True, save='_smarca2_violin_type.png')\n",
    "    \n",
    "    # 计算SMARCA2在不同组中的表达统计\n",
    "    smarca2_expr = adata.raw[:, 'SMARCA2'].X\n",
    "    if hasattr(smarca2_expr, 'toarray'):\n",
    "        smarca2_expr = smarca2_expr.toarray().flatten()\n",
    "    \n",
    "    # 添加SMARCA2表达到obs中\n",
    "    adata.obs['SMARCA2_expr'] = smarca2_expr\n",
    "    \n",
    "    # 按组计算统计\n",
    "    smarca2_stats = adata.obs.groupby('Type')['SMARCA2_expr'].agg(['mean', 'median', 'std'])\n",
    "    print(\"\\nSMARCA2表达统计:\")\n",
    "    print(smarca2_stats)\n",
    "    \n",
    "    # 按细胞类型计算统计\n",
    "    smarca2_celltype_stats = adata.obs.groupby('cell_type_auto')['SMARCA2_expr'].agg(['mean', 'median', 'std'])\n",
    "    print(\"\\nSMARCA2在不同细胞类型中的表达统计:\")\n",
    "    print(smarca2_celltype_stats)\n",
    "    \n",
    "else:\n",
    "    print(\"✗ SMARCA2基因不在数据中\")\n",
    "    print(\"可能的原因：1) 基因名称不同 2) 基因在质控中被过滤\")\n",
    "    \n",
    "    # 搜索可能的SMARCA2相关基因\n",
    "    possible_names = ['SMARCA2', 'BRM', 'BAF190B', 'SNF2L2']\n",
    "    found_genes = []\n",
    "    for name in possible_names:\n",
    "        if name in adata.raw.var_names:\n",
    "            found_genes.append(name)\n",
    "    \n",
    "    if found_genes:\n",
    "        print(f\"找到可能相关的基因: {found_genes}\")\n",
    "        # 使用找到的第一个基因进行分析\n",
    "        target_gene = found_genes[0]\n",
    "        print(f\"使用 {target_gene} 进行分析\")\n",
    "        \n",
    "        # 重复上述分析\n",
    "        sc.pl.umap(adata, color=target_gene, use_raw=True, \n",
    "                   title=f'{target_gene} Expression', save=f'_{target_gene.lower()}_umap.png')\n",
    "    else:\n",
    "        print(\"未找到SMARCA2相关基因\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6cad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SMARCA2 在癌细胞中的表达差异 ---\n",
    "\n",
    "# 确定目标基因\n",
    "target_gene = 'SMARCA2' if 'SMARCA2' in adata.raw.var_names else None\n",
    "if target_gene is None:\n",
    "    possible_names = ['SMARCA2', 'BRM', 'BAF190B', 'SNF2L2']\n",
    "    for name in possible_names:\n",
    "        if name in adata.raw.var_names:\n",
    "            target_gene = name\n",
    "            break\n",
    "\n",
    "if target_gene and cancer_cells.n_obs > 0:\n",
    "    print(f\"分析 {target_gene} 在癌细胞中的表达差异\")\n",
    "    \n",
    "    # 在癌细胞中比较两组的表达\n",
    "    cancer_smarca2_expr = cancer_cells.raw[:, target_gene].X\n",
    "    if hasattr(cancer_smarca2_expr, 'toarray'):\n",
    "        cancer_smarca2_expr = cancer_smarca2_expr.toarray().flatten()\n",
    "    \n",
    "    cancer_cells.obs[f'{target_gene}_expr'] = cancer_smarca2_expr\n",
    "    \n",
    "    # 统计分析\n",
    "    cancer_smarca2_stats = cancer_cells.obs.groupby('Type')[f'{target_gene}_expr'].agg(['mean', 'median', 'std', 'count'])\n",
    "    print(f\"\\n{target_gene}在癌细胞中的表达统计:\")\n",
    "    print(cancer_smarca2_stats)\n",
    "    \n",
    "    # 可视化\n",
    "    sc.pl.violin(cancer_cells, keys=target_gene, groupby='Type', \n",
    "                 use_raw=True, save=f'_{target_gene.lower()}_cancer_violin.png')\n",
    "    \n",
    "    sc.pl.boxplot(cancer_cells, keys=target_gene, groupby='Type', \n",
    "                  use_raw=True, save=f'_{target_gene.lower()}_cancer_boxplot.png')\n",
    "    \n",
    "    # 统计检验\n",
    "    from scipy import stats\n",
    "    \n",
    "    refractory_expr = cancer_cells.obs[cancer_cells.obs['Type'] == 'refractory'][f'{target_gene}_expr']\n",
    "    sensitive_expr = cancer_cells.obs[cancer_cells.obs['Type'] == 'sensitive'][f'{target_gene}_expr']\n",
    "    \n",
    "    if len(refractory_expr) > 0 and len(sensitive_expr) > 0:\n",
    "        # 执行Mann-Whitney U检验\n",
    "        statistic, p_value = stats.mannwhitneyu(refractory_expr, sensitive_expr, alternative='two-sided')\n",
    "        \n",
    "        print(f\"\\n{target_gene}表达差异统计检验:\")\n",
    "        print(f\"Mann-Whitney U统计量: {statistic}\")\n",
    "        print(f\"P值: {p_value:.6f}\")\n",
    "        \n",
    "        if p_value < 0.05:\n",
    "            print(\"结论: 两组间存在显著差异\")\n",
    "        else:\n",
    "            print(\"结论: 两组间无显著差异\")\n",
    "    \n",
    "    print(f\"\\n{target_gene}在癌细胞中的分析完成\")\n",
    "else:\n",
    "    print(\"无法进行SMARCA2在癌细胞中的分析\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4514a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SMARCA2 共表达基因分析 ---\n",
    "\n",
    "if target_gene and cancer_cells.n_obs > 0:\n",
    "    print(f\"分析与 {target_gene} 共表达的基因\")\n",
    "    \n",
    "    # 获取癌细胞的表达矩阵\n",
    "    cancer_expr_matrix = cancer_cells.raw.X\n",
    "    if hasattr(cancer_expr_matrix, 'toarray'):\n",
    "        cancer_expr_matrix = cancer_expr_matrix.toarray()\n",
    "    \n",
    "    # 获取目标基因的表达\n",
    "    target_gene_idx = list(cancer_cells.raw.var_names).index(target_gene)\n",
    "    target_expr = cancer_expr_matrix[:, target_gene_idx]\n",
    "    \n",
    "    # 计算与所有其他基因的相关性\n",
    "    correlations = []\n",
    "    gene_names = []\n",
    "    \n",
    "    for i, gene in enumerate(cancer_cells.raw.var_names):\n",
    "        if gene != target_gene:\n",
    "            gene_expr = cancer_expr_matrix[:, i]\n",
    "            # 计算Pearson相关系数\n",
    "            corr, p_val = stats.pearsonr(target_expr, gene_expr)\n",
    "            correlations.append(corr)\n",
    "            gene_names.append(gene)\n",
    "    \n",
    "    # 创建相关性结果DataFrame\n",
    "    corr_df = pd.DataFrame({\n",
    "        'gene': gene_names,\n",
    "        'correlation': correlations\n",
    "    })\n",
    "    \n",
    "    # 按相关性绝对值排序\n",
    "    corr_df['abs_correlation'] = corr_df['correlation'].abs()\n",
    "    corr_df = corr_df.sort_values('abs_correlation', ascending=False)\n",
    "    \n",
    "    print(f\"\\n与{target_gene}表达最相关的前20个基因:\")\n",
    "    print(corr_df.head(20)[['gene', 'correlation']])\n",
    "    \n",
    "    # 保存共表达分析结果\n",
    "    corr_df.to_csv(os.path.join(output_dir, f'{target_gene}_coexpression_analysis.csv'), index=False)\n",
    "    \n",
    "    # 可视化Top相关基因\n",
    "    top_pos_genes = corr_df.head(5)['gene'].tolist()  # 正相关\n",
    "    top_neg_genes = corr_df.tail(5)['gene'].tolist()  # 负相关\n",
    "    \n",
    "    # 检查基因是否在高变异基因中\n",
    "    available_pos_genes = [g for g in top_pos_genes if g in cancer_cells.var_names]\n",
    "    available_neg_genes = [g for g in top_neg_genes if g in cancer_cells.var_names]\n",
    "    \n",
    "    if available_pos_genes:\n",
    "        print(f\"\\n可视化与{target_gene}正相关的基因: {available_pos_genes}\")\n",
    "        sc.pl.umap(cancer_cells, color=[target_gene] + available_pos_genes[:3], \n",
    "                   use_raw=True, save=f'_{target_gene.lower()}_positive_coexpression.png')\n",
    "    \n",
    "    if available_neg_genes:\n",
    "        print(f\"\\n可视化与{target_gene}负相关的基因: {available_neg_genes}\")\n",
    "        sc.pl.umap(cancer_cells, color=[target_gene] + available_neg_genes[:3], \n",
    "                   use_raw=True, save=f'_{target_gene.lower()}_negative_coexpression.png')\n",
    "    \n",
    "    # 基于SMARCA2表达水平定义细胞亚群\n",
    "    smarca2_median = np.median(cancer_cells.obs[f'{target_gene}_expr'])\n",
    "    cancer_cells.obs[f'{target_gene}_high'] = cancer_cells.obs[f'{target_gene}_expr'] > smarca2_median\n",
    "    cancer_cells.obs[f'{target_gene}_group'] = cancer_cells.obs[f'{target_gene}_high'].map({True: 'High', False: 'Low'})\n",
    "    \n",
    "    print(f\"\\n基于{target_gene}表达水平的细胞分组:\")\n",
    "    print(cancer_cells.obs[f'{target_gene}_group'].value_counts())\n",
    "    \n",
    "    # 可视化SMARCA2高低表达细胞的分布\n",
    "    sc.pl.umap(cancer_cells, color=f'{target_gene}_group', \n",
    "               save=f'_{target_gene.lower()}_high_low_groups.png')\n",
    "    \n",
    "    print(f\"\\n{target_gene}共表达分析完成\")\n",
    "else:\n",
    "    print(\"无法进行共表达分析\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## 步骤六：为 Geneformer 模拟实验做准备\n",
    "\n",
    "最后一步是生成 Geneformer 所需的输入文件。这通常包括定义好的细胞群的表达谱和用于模拟的基因列表。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb615da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 定义和导出细胞状态 ---\n",
    "\n",
    "print(\"为Geneformer模拟实验准备输入文件...\")\n",
    "\n",
    "# 创建Geneformer输出目录\n",
    "geneformer_dir = os.path.join(output_dir, 'geneformer_input')\n",
    "if not os.path.exists(geneformer_dir):\n",
    "    os.makedirs(geneformer_dir)\n",
    "\n",
    "if cancer_cells.n_obs > 0:\n",
    "    # 1. 化疗敏感的癌细胞\n",
    "    sensitive_cancer_cells = cancer_cells[cancer_cells.obs['Type'] == 'sensitive'].copy()\n",
    "    \n",
    "    # 2. 化疗耐药的癌细胞\n",
    "    refractory_cancer_cells = cancer_cells[cancer_cells.obs['Type'] == 'refractory'].copy()\n",
    "    \n",
    "    print(f\"敏感癌细胞数量: {sensitive_cancer_cells.n_obs}\")\n",
    "    print(f\"耐药癌细胞数量: {refractory_cancer_cells.n_obs}\")\n",
    "    \n",
    "              # 文件1: 差异表达基因列表 (用于评估模拟效果)\n",
    "     if not deg_results.empty:\n",
    "         deg_list_path = os.path.join(geneformer_dir, 'deg_gene_list.csv')\n",
    "         deg_results_for_geneformer = deg_results[['names', 'logfoldchanges', 'pvals_adj']].copy()\n",
    "         deg_results_for_geneformer.columns = ['gene', 'log2fc', 'padj']\n",
    "         deg_results_for_geneformer.to_csv(deg_list_path, index=False)\n",
    "         print(f\"差异基因列表已保存到: {deg_list_path}\")\n",
    "    \n",
    "    # 文件2: 敏感癌细胞的平均表达谱 (作为模拟的基线细胞状态)\n",
    "    if sensitive_cancer_cells.n_obs > 0:\n",
    "        baseline_expression = np.mean(sensitive_cancer_cells.raw.X, axis=0)\n",
    "        if hasattr(baseline_expression, 'A1'):\n",
    "            baseline_expression = baseline_expression.A1\n",
    "        \n",
    "        baseline_df = pd.DataFrame({\n",
    "            'gene': sensitive_cancer_cells.raw.var_names,\n",
    "            'mean_expression': baseline_expression\n",
    "        })\n",
    "        baseline_df = baseline_df.sort_values('mean_expression', ascending=False)\n",
    "        \n",
    "        baseline_path = os.path.join(geneformer_dir, 'baseline_sensitive_cancer_cells.csv')\n",
    "        baseline_df.to_csv(baseline_path, index=False)\n",
    "        print(f\"基线表达谱已保存到: {baseline_path}\")\n",
    "    \n",
    "    # 文件3: 耐药癌细胞的平均表达谱 (作为目标状态)\n",
    "    if refractory_cancer_cells.n_obs > 0:\n",
    "        target_expression = np.mean(refractory_cancer_cells.raw.X, axis=0)\n",
    "        if hasattr(target_expression, 'A1'):\n",
    "            target_expression = target_expression.A1\n",
    "        \n",
    "        target_df = pd.DataFrame({\n",
    "            'gene': refractory_cancer_cells.raw.var_names,\n",
    "            'mean_expression': target_expression\n",
    "        })\n",
    "        target_df = target_df.sort_values('mean_expression', ascending=False)\n",
    "        \n",
    "        target_path = os.path.join(geneformer_dir, 'target_refractory_cancer_cells.csv')\n",
    "        target_df.to_csv(target_path, index=False)\n",
    "        print(f\"目标表达谱已保存到: {target_path}\")\n",
    "    \n",
    "    # 文件4: SMARCA2共表达基因网络\n",
    "    if target_gene and 'corr_df' in locals():\n",
    "        coexpr_path = os.path.join(geneformer_dir, f'{target_gene}_coexpression_network.csv')\n",
    "        corr_df.to_csv(coexpr_path, index=False)\n",
    "        print(f\"{target_gene}共表达网络已保存到: {coexpr_path}\")\n",
    "    \n",
    "    print(f\"\\n所有Geneformer输入文件已保存到: {geneformer_dir}\")\n",
    "else:\n",
    "    print(\"无癌细胞数据，无法生成Geneformer输入文件\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1510252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 生成分析总结报告 ---\n",
    "\n",
    "print(\"生成分析总结报告...\")\n",
    "\n",
    "# 创建总结报告\n",
    "summary_report = f\"\"\"\n",
    "# 卵巢癌化疗耐药性单细胞RNA-seq分析总结报告\n",
    "\n",
    "## 数据概况\n",
    "- 总细胞数: {adata.n_obs}\n",
    "- 总基因数: {adata.n_vars}\n",
    "- 样本数: {len(adata.obs['Sample'].unique())}\n",
    "- 耐药组样本: {len(adata.obs[adata.obs['Type'] == 'refractory']['Sample'].unique())}\n",
    "- 敏感组样本: {len(adata.obs[adata.obs['Type'] == 'sensitive']['Sample'].unique())}\n",
    "\n",
    "## 细胞类型分布\n",
    "{adata.obs['cell_type_auto'].value_counts().to_string()}\n",
    "\n",
    "## 癌细胞分析结果\n",
    "- 癌细胞总数: {cancer_cells.n_obs if cancer_cells.n_obs > 0 else 0}\n",
    "- 耐药组癌细胞: {len(cancer_cells.obs[cancer_cells.obs['Type'] == 'refractory']) if cancer_cells.n_obs > 0 else 0}\n",
    "- 敏感组癌细胞: {len(cancer_cells.obs[cancer_cells.obs['Type'] == 'sensitive']) if cancer_cells.n_obs > 0 else 0}\n",
    "\n",
    "## 差异表达基因分析\n",
    "- 显著差异基因数: {len(deg_results) if not deg_results.empty else 0}\n",
    "\n",
    "## SMARCA2分析结果\n",
    "- 目标基因: {target_gene if target_gene else 'SMARCA2未找到'}\n",
    "\"\"\"\n",
    "\n",
    "if target_gene and cancer_cells.n_obs > 0:\n",
    "    summary_report += f\"\"\"\n",
    "- {target_gene}在耐药组平均表达: {cancer_cells.obs[cancer_cells.obs['Type'] == 'refractory'][f'{target_gene}_expr'].mean():.4f}\n",
    "- {target_gene}在敏感组平均表达: {cancer_cells.obs[cancer_cells.obs['Type'] == 'sensitive'][f'{target_gene}_expr'].mean():.4f}\n",
    "\"\"\"\n",
    "\n",
    "summary_report += f\"\"\"\n",
    "\n",
    "## 输出文件\n",
    "- 主要结果保存在: {output_dir}\n",
    "- Geneformer输入文件保存在: {geneformer_dir}\n",
    "- 处理后的AnnData对象将保存为: processed_adata.h5ad\n",
    "\n",
    "## 下一步建议\n",
    "1. 根据可视化结果调整细胞类型注释\n",
    "2. 深入分析感兴趣的差异表达基因\n",
    "3. 使用生成的输入文件进行Geneformer模拟\n",
    "4. 验证关键发现的生物学意义\n",
    "\n",
    "分析完成时间: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\"\n",
    "\n",
    "# 保存总结报告\n",
    "report_path = os.path.join(output_dir, 'analysis_summary_report.txt')\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(summary_report)\n",
    "\n",
    "print(f\"分析总结报告已保存到: {report_path}\")\n",
    "print(summary_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4f5461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 保存最终的AnnData对象 ---\n",
    "\n",
    "print(\"保存最终处理的数据...\")\n",
    "\n",
    "# 最后，保存最终的AnnData对象，以便未来快速加载和探索\n",
    "final_adata_path = os.path.join(output_dir, 'processed_adata.h5ad')\n",
    "adata.write(final_adata_path)\n",
    "\n",
    "print(f\"最终处理好的AnnData对象已保存到: {final_adata_path}\")\n",
    "\n",
    "# 也保存癌细胞的子集数据\n",
    "if cancer_cells.n_obs > 0:\n",
    "    cancer_adata_path = os.path.join(output_dir, 'cancer_cells_adata.h5ad')\n",
    "    cancer_cells.write(cancer_adata_path)\n",
    "    print(f\"癌细胞子集数据已保存到: {cancer_adata_path}\")\n",
    "\n",
    "print(\"\\n🎉 所有分析步骤完成！\")\n",
    "print(\"=\" * 60)\n",
    "print(\"主要输出文件:\")\n",
    "print(f\"1. 完整分析数据: {final_adata_path}\")\n",
    "print(f\"2. 分析报告: {report_path}\")\n",
    "print(f\"3. Geneformer输入文件: {geneformer_dir}\")\n",
    "print(f\"4. 各类图表: {output_dir}\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n现在您可以:\")\n",
    "print(\"1. 查看生成的图表和分析结果\")\n",
    "print(\"2. 根据需要调整参数重新运行特定步骤\")\n",
    "print(\"3. 使用Geneformer输入文件进行BRM敲除模拟\")\n",
    "print(\"4. 进一步验证关键发现\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## 分析流程总结\n",
    "\n",
    "这个Notebook实现了完整的单细胞RNA-seq分析流程，专门针对卵巢癌化疗耐药性研究：\n",
    "\n",
    "### 已完成的分析步骤：\n",
    "\n",
    "1. **数据加载与质控** - 加载UMI计数和细胞注释，进行质量控制过滤\n",
    "2. **数据整合与降维** - 标准化、批次校正、PCA、UMAP降维和聚类\n",
    "3. **细胞类型注释** - 基于标记基因识别不同细胞类型\n",
    "4. **差异分析** - 比较耐药组vs敏感组的细胞组成和基因表达差异\n",
    "5. **SMARCA2深度分析** - 聚焦目标基因的表达模式和共表达网络\n",
    "6. **Geneformer准备** - 生成用于后续模拟实验的输入文件\n",
    "\n",
    "### 关键输出文件：\n",
    "\n",
    "- **processed_adata.h5ad**: 完整的处理后数据\n",
    "- **cancer_cells_adata.h5ad**: 癌细胞子集数据\n",
    "- **analysis_summary_report.txt**: 分析总结报告\n",
    "- **geneformer_input/**: Geneformer模拟实验输入文件\n",
    "- 各种可视化图表和统计结果\n",
    "\n",
    "### 下一步工作：\n",
    "\n",
    "1. **结果验证**: 检查细胞类型注释的准确性\n",
    "2. **深入分析**: 探索感兴趣的差异表达基因和通路\n",
    "3. **Geneformer模拟**: 使用生成的文件进行BRM敲除模拟\n",
    "4. **生物学验证**: 设计实验验证关键发现\n",
    "\n",
    "### 注意事项：\n",
    "\n",
    "- 某些步骤可能需要根据实际数据调整参数\n",
    "- 建议在真实数据上运行前先检查数据格式和路径\n",
    "- 部分可选包（如Harmony、gseapy）需要单独安装\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739847bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
