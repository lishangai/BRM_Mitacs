# 项目组织规范

## 项目结构概述：
所有 Python 代码在 src/
所有 R 代码和其直接产出在 r_analysis/
所有 Python 代码的产出以及项目最终报告所用的精选图表/表格，都放在results/ 目录下的一个与脚本同名的文件夹下
数据在 data/
探索性 Notebook 在 notebooks/
项目文档在 docs/

## 脚本输出的设置方法：
自动检测脚本名称：脚本会自动获取自己的文件名（例如 missing_data_statistics_english）。
构建默认输出路径：根据脚本名，自动构建输出路径，格式为 ../results/<脚本名>/。
智能创建目录：如果该目录不存在，脚本会自动创建它。
保留手动覆盖选项：您依然可以使用 --output_dir 或 -o 参数来指定一个不同的输出目录，这为您提供了灵活性。



好的，非常乐意为您总结这一套高度规范、健壮且可扩展的数据科学项目管理方法。您可以将其视为未来所有项目的“黄金标准”或“最佳实践模板”。

这套方法论的核心是**“关注点分离” (Separation of Concerns)** 和 **“路径独立性” (Path Independence)**。

---

### **方法论总结：专业数据科学项目结构与工作流**

#### **第一部分：清晰的目录结构**

我们为项目的不同组成部分创建了专属的、逻辑清晰的目录，确保任何文件都能被快速定位。

*   **`src/`**: **存放所有可复用的 Python 源代码 (`.py`)。**
    *   **目的**：将核心逻辑与数据、报告、探索性分析等完全分离开。这是项目的“引擎室”。

*   **`r_analysis/` (或其他语言，如 `julia_analysis/`)**: **存放特定语言的分析代码及其内聚结果。**
    *   **目的**：为多语言项目提供清晰的隔离区，保持各个分析模块的独立性和完整性。

*   **`data/`**: **存放所有数据，并严格分为两类。**
    *   **`data/raw/`**: 存放**永不修改**的原始数据。这是数据分析的唯一“事实来源”，保证了可复现性。
    *   **`data/processed/`**: 存放经过清洗、预处理、合并后随时可以用于分析的“干净”数据。

*   **`notebooks/`**: **存放探索性分析、快速原型验证和一次性实验。**
    *   **目的**：将临时的、非正式的探索性代码（如 Jupyter Notebook, R Markdown）与最终的、稳定的生产脚本分离开，避免混淆。

*   **`results/`**: **存放所有由代码生成的、用于最终报告的成果。**
    *   **目的**：提供一个统一的、集中的输出地点，避免结果文件散落在项目各处。通常内部分为：
        *   `results/figures/`: 存放所有图表。
        *   `results/tables/`: 存放所有输出的数据表 (CSV, Excel)。
        *   `results/reports/`: 存放生成的文本报告、模型对象等。

*   **`docs/`**: **存放所有手写的、给人阅读的项目文档。**
    *   **目的**：集中管理项目介绍、分析报告的最终版本 (PDF/Markdown)、背景资料等。

#### **第二部分：健壮的路径管理（核心！）**

这是确保项目代码健壮、可移植的关键。

*   **原则**：**绝不硬编码任何绝对或相对路径。** 所有路径都应基于动态计算出的**项目根目录**来构建。
*   **Python 实现 (`pathlib`)**:
    1.  在脚本顶部定义项目根目录：
        ```python
        from pathlib import Path
        PROJECT_ROOT = Path(__file__).resolve().parent.parent 
        ```
    2.  所有文件路径都从 `PROJECT_ROOT` 开始构建：
        ```python
        # 读取输入
        input_path = PROJECT_ROOT / "data" / "raw" / "source.csv"
        # 定义输出
        output_path = PROJECT_ROOT / "results" / "figures" / "my_plot.png"
        ```
*   **R 实现 (`here` 包)**:
    1.  加载 `here` 库：`library(here)`
    2.  使用 `here()` 函数构建所有路径：
        ```R
        # here() 会自动找到项目根目录
        input_path <- here("data", "raw", "source.csv")
        output_path <- here("results", "figures", "my_plot.png")
        ```

#### **第三部分：规范化的输出管理**

为了保持 `results` 目录的整洁，我们为每个分析脚本创建了专属的输出子目录。

*   **实现方式**：在脚本中，动态获取当前脚本的文件名，并用它在 `results` 目录下创建一个同名文件夹。
    ```python
    # 在 Python 脚本的 main 函数中
    script_name = Path(__file__).stem # 获取脚本名，如 "brm_analysis"
    output_dir = PROJECT_ROOT / "results" / script_name
    output_dir.mkdir(parents=True, exist_ok=True) # 创建目录，如果已存在则忽略
    ```

---

**总结起来，这套方法论能带给您的好处是：**

*   **高度可维护性**：结构清晰，任何人都能快速上手。
*   **代码健壮性**：彻底摆脱因路径错误导致的各种问题。
*   **完全可移植性**：项目可以被安全地移动到任何地方或分享给任何人，无需修改代码。
*   **支持协同工作**：清晰的规范使得团队协作变得简单高效。
*   **专业性**：这是业界广泛采用的标准实践，能让您的项目看起来非常专业。

将这个模板应用到您的项目中，是提升代码质量和开发效率的巨大飞跃。




好的，我们来系统地总结一下在这套新架构下，我们为脚本建立的、高度规范的**输入与输出（I/O）规则**。这套规则是确保项目健壮性、可维护性和易用性的核心。

### **输入/输出（I/O）规范总结**

#### **一、 核心原则：动态路径与根目录基准**

所有I/O操作都严格遵守一个核心原则：**路径独立性**。

*   **动态计算项目根目录**：所有脚本在启动时，都会首先通过代码（如 Python 的 `pathlib`）动态定位到项目的根目录（`BRM_Mitacs/`）。这个根目录是所有路径计算的“锚点”。
    ```python
    # Python中的实现
    from pathlib import Path
    PROJECT_ROOT = Path(__file__).resolve().parent.parent
    ```
*   **禁止硬编码**：代码中**绝不出现**任何写死的绝对路径（如 `F:/...`）或脆弱的相对路径（如 `../`），所有路径都必须从 `PROJECT_ROOT` 开始构建。

---

#### **二、 输入（Input）规范**

对于脚本需要读取的文件，我们采用灵活且明确的命令行参数机制。

*   **通过命令行参数指定**：脚本通过 `argparse` 等工具定义一个专门的输入文件参数（如 `--input_file` 或 `-i`）。
*   **路径相对于根目录**：用户在命令行中提供的路径，我们约定它总是**相对于项目根目录**的。例如，`data/processed/working.csv`。
*   **脚本内部构建绝对路径**：脚本接收到这个相对路径后，会立即用 `PROJECT_ROOT` 与之结合，形成一个**绝对且可靠**的路径供后续程序使用。
    ```python
    # 脚本内部逻辑
    user_provided_path = args.input_file
    absolute_input_path = PROJECT_ROOT / user_provided_path
    # 后续使用 absolute_input_path 读取文件
    ```
*   **可设默认值**：对于常用的、核心的输入文件，我们可以为其设置一个默认路径（如 `data/processed/working.csv`），这样用户无需每次都输入，大大提升了便利性。

---

#### **三、 输出（Output）规范**

对于脚本运行产生的任何结果（文件、图表、报告），我们建立了一套自动化的、有组织的存储规则。

*   **统一的顶级输出目录**：所有最终成果都必须保存在项目根目录下的 `results/` 文件夹内。
*   **脚本同名子目录**：为了避免不同分析任务的结果混杂在一起，我们规定，每个脚本的输出都应保存在 `results/` 下一个与**该脚本文件名相同**的子目录中。
    *   例如，`brm_analysis_csv.py` 的所有输出都会被自动放入 `results/brm_analysis_csv/` 文件夹。
*   **自动化实现**：这个路径是在脚本内部动态构建的，并且脚本会自动检查并创建该目录，用户无需任何手动操作。
    ```python
    # 脚本内部逻辑
    script_name = Path(__file__).stem  # e.g., "brm_analysis_csv"
    output_directory = PROJECT_ROOT / "results" / script_name
    output_directory.mkdir(parents=True, exist_ok=True) # 确保目录存在
    # 所有文件都保存到 output_directory 中
    ```
*   **灵活性**：虽然有此自动化规则，但我们依然保留了 `--output_dir` 或 `-o` 这样的命令行参数，允许用户在需要时手动覆盖默认的输出位置，提供了必要的灵活性。

---

**总结起来，这套 I/O 规范的优势是：**

*   **清晰**：任何人看到命令行或代码，都能立刻明白文件的来源和去向。
*   **健壮**：彻底消除了因运行位置改变而导致的“文件找不到”错误。
*   **整洁**：`results` 目录自动保持高度的组织性，每个分析任务的结果都井井有条。
*   **便捷**：通过设置默认输入，简化了日常操作，同时保留了处理不同数据的能力。

这套规范是连接我们优秀的项目结构和健壮的代码逻辑之间的桥梁，是整个项目能够高效、可靠运行的关键。





好的，非常乐意为您总结这套我们刚刚实现的、健壮且实用的日志记录规范。

### **日志记录规范总结**

这套规范的核心目标是：**在不影响正常交互体验的前提下，完整、自动地捕获程序每一次运行的“足迹”，以便于调试、复现和审计。**

#### **一、 核心原则：输出重定向与过程无感**

*   **非侵入式记录 (Non-intrusive Logging)**：我们没有在代码的每个角落都添加 `log.info()` 或 `log.debug()` 这样的日志记录语句。而是从更高层面，通过**重定向标准输出 (`stdout`)** 的方式，来捕获所有原本要打印到控制台的信息。
*   **用户体验一致**：对用户来说，程序的交互体验几乎没有变化。在运行时，他们依然可以像往常一样在控制台看到实时的进度和结果。日志记录是在“幕后”自动完成的。

#### **二、 实现机制：Tee (三通)**

我们实现这个功能的技术，可以形象地称为“Tee”或“三通”，就像一个三通水管，将信息流同时引向多个目的地。

1.  **定义 `Tee` 类**：我们创建了一个简单的辅助类，它的 `write` 方法会将接收到的任何文本，依次写入到它所管理的所有目标（例如，原始的控制台和日志文件）中。
    ```python
    class Tee:
        def __init__(self, *files):
            self.files = files
        def write(self, obj):
            for f in self.files:
                f.write(obj)
                f.flush() # 确保立即写入
    ```

2.  **重定向 `sys.stdout`**：在主程序的入口处，我们将系统的标准输出 `sys.stdout` “劫持”过来，替换成我们 `Tee` 类的实例。
    ```python
    # 保存原始的控制台输出
    original_stdout = sys.stdout
    # 打开日志文件
    log_file = open('analysis_log.txt', 'w')
    # 将标准输出重定向到 Tee 实例，目的地是控制台和日志文件
    sys.stdout = Tee(original_stdout, log_file)
    ```
    从这一刻起，程序中所有的 `print()` 语句实际上都在调用我们 `Tee` 类的 `write` 方法。

#### **三、 输出位置与命名规范**

日志文件本身也遵循我们之前建立的输出规范。

*   **位置**：日志文件被视为分析过程的一种**产出**，因此它被保存在对应脚本的专属输出目录中（例如 `results/brm_analysis_csv/`）。
*   **命名**：日志文件有一个固定的、描述性的名称，如 `analysis_log.txt`，便于查找。

#### **四、 健壮性保障：`try...finally`**

为了确保无论程序是成功执行还是中途崩溃，我们的操作都“有始有终”，我们将核心逻辑包裹在 `try...finally` 块中。

*   **`try` 块**：包含所有主要的分析代码。
*   **`finally` 块**：无论 `try` 块中发生了什么（即使是抛出异常），`finally` 块中的代码都**保证会被执行**。我们在这里执行清理工作：
    1.  **恢复 `sys.stdout`**：将 `sys.stdout` 恢复为原始的控制台，确保后续（如果有）的程序行为不受影响。
    2.  **关闭文件句柄**：妥善地关闭日志文件，确保所有缓冲区的日志都被写入磁盘。
    ```python
    try:
        # ... 主要分析代码 ...
    finally:
        sys.stdout = original_stdout # 恢复
        log_file.close()           # 关闭
    ```

---

**总结起来，这套日志规范的优势是：**

*   **自动化**：无需修改成百上千的 `print` 语句，即可实现全面的日志记录。
*   **完整性**：能够捕获包括程序启动信息、进度更新、最终总结、甚至是错误追溯在内的所有控制台输出。
*   **可追溯性**：为每一次分析运行提供了永久的、不可变的记录，是科学复现和问题排查的基石。
*   **代码整洁**：将日志记录的逻辑集中在 `main` 函数的入口和出口，保持了核心分析代码的纯粹和整洁。